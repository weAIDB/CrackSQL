[
    {
        "Type": [
            "bigint",
            "int8"
        ],
        "Description": [
            "signed eight-byte integer",
            "large-range integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "The types <code>smallint</code>, <code>integer</code>, and <code>bigint</code> store whole numbers, that is, numbers without fractional components, of various ranges. Attempts to store values outside of the allowed range will result in an error.",
            "The type <code>integer</code> is the common choice, as it offers the best balance between range, storage size, and performance. The <code>smallint</code> type is generally only used if disk space is at a premium. The <code>bigint</code> type is designed to be used when the range of the <code>integer</code> type is insufficient.",
            "SQL only specifies the integer types <code>integer</code> (or <code>int</code>), <code>smallint</code>, and <code>bigint</code>. The type names <code>int2</code>, <code>int4</code>, and <code>int8</code> are extensions, which are also used by some other SQL database systems.",
            "The type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column."
        ],
        "Storage Size": "8 bytes",
        "Range": "-9223372036854775808 to +9223372036854775807",
        "Tree": [
            "(numeric BIGINT)",
            "(identifier INT8)"
        ]
    },
    {
        "Type": [
            "bigserial",
            "serial8"
        ],
        "Description": [
            "autoincrementing eight-byte integer",
            "large autoincrementing integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "The data types <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are not true types, but merely a notational convenience for creating unique identifier columns (similar to the <code>AUTO_INCREMENT</code> property supported by some other databases). In the current implementation, specifying:",
            "Because <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are implemented using sequences, there may be \"holes\" or gaps in the sequence of values which appears in the column, even if no rows are ever deleted. A value allocated from the sequence is still \"used up\" even if a row containing that value is never successfully inserted into the table column. This may happen, for example, if the inserting transaction rolls back. See <code>nextval()</code> in Section 9.16 for details.",
            "The type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column."
        ],
        "Storage Size": "8 bytes",
        "Range": "1 to 9223372036854775807",
        "Tree": [
            "(identifier BIGSERIAL)",
            "(identifier SERIAL8)"
        ]
    },
    {
        "Type": [
            "smallint",
            "int2"
        ],
        "Description": [
            "signed two-byte integer",
            "small-range integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "The types <code>smallint</code>, <code>integer</code>, and <code>bigint</code> store whole numbers, that is, numbers without fractional components, of various ranges. Attempts to store values outside of the allowed range will result in an error.",
            "The type <code>integer</code> is the common choice, as it offers the best balance between range, storage size, and performance. The <code>smallint</code> type is generally only used if disk space is at a premium. The <code>bigint</code> type is designed to be used when the range of the <code>integer</code> type is insufficient.",
            "SQL only specifies the integer types <code>integer</code> (or <code>int</code>), <code>smallint</code>, and <code>bigint</code>. The type names <code>int2</code>, <code>int4</code>, and <code>int8</code> are extensions, which are also used by some other SQL database systems.",
            "The type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column."
        ],
        "Storage Size": "2 bytes",
        "Range": "-32768 to +32767",
        "Tree": [
            "(numeric SMALLINT)",
            "(identifier INT2)"
        ]
    },
    {
        "Type": [
            "numeric ( p, s )",
            "decimal ( p, s )",
            "numeric",
            "decimal"
        ],
        "Description": [
            "exact numeric of selectable precision",
            "user-specified precision, exact",
            "user-specified precision, exact"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "The type <code>numeric</code> can store numbers with a very large number of digits. It is especially recommended for storing monetary amounts and other quantities where exactness is required. Calculations with <code>numeric</code> values yield exact results where possible, e.g., addition, subtraction, multiplication. However, calculations on <code>numeric</code> values are very slow compared to the integer types, or to the floating-point types described in the next section.",
            "We use the following terms below: The precision of a <code>numeric</code> is the total count of significant digits in the whole number, that is, the number of digits to both sides of the decimal point. The scale of a <code>numeric</code> is the count of decimal digits in the fractional part, to the right of the decimal point. So the number 23.5141 has a precision of 6 and a scale of 4. Integers can be considered to have a scale of zero.",
            "Both the maximum precision and the maximum scale of a <code>numeric</code> column can be configured. To declare a column of type <code>numeric</code> use the syntax:",
            "<code>\nNUMERIC(precision, scale)\n</code>",
            "<code>\nNUMERIC(precision)\n</code>",
            "<code>\nNUMERIC\n</code>",
            "without any precision or scale creates a column in which numeric values of any precision and scale can be stored, up to the implementation limit on precision. A column of this kind will not coerce input values to any particular scale, whereas <code>numeric</code> columns with a declared scale will coerce input values to that scale. (The SQL standard requires a default scale of 0, i.e., coercion to integer precision. We find this a bit useless. If you're concerned about portability, always specify the precision and scale explicitly.)",
            "The maximum allowed precision when explicitly specified in the type declaration is 1000; <code>NUMERIC</code> without a specified precision is subject to the limits described in Table 8.2.",
            "Numeric values are physically stored without any extra leading or trailing zeroes. Thus, the declared precision and scale of a column are maximums, not fixed allocations. (In this sense the <code>numeric</code> type is more akin to <code>varchar(n)</code> than to <code>char(n)</code>.) The actual storage requirement is two bytes for each group of four decimal digits, plus three to eight bytes overhead.",
            "In addition to ordinary numeric values, the <code>numeric</code> type allows the special value <code>NaN</code>, meaning \"not-a-number\". Any operation on <code>NaN</code> yields another <code>NaN</code>. When writing this value as a constant in an SQL command, you must put quotes around it, for example <code>UPDATE table SET x = 'NaN'</code>. On input, the string <code>NaN</code> is recognized in a case-insensitive manner.",
            "In most implementations of the \"not-a-number\" concept, <code>NaN</code> is not considered equal to any other numeric value (including <code>NaN</code>). In order to allow <code>numeric</code> values to be sorted and used in tree-based indexes, PostgreSQL treats <code>NaN</code> values as equal, and greater than all non-<code>NaN</code> values.",
            "The types <code>decimal</code> and <code>numeric</code> are equivalent. Both types are part of the SQL standard.",
            "When rounding values, the <code>numeric</code> type rounds ties away from zero, while (on most machines) the <code>real</code> and <code>double precision</code> types round ties to the nearest even number. For example:",
            "<code>\nSELECT x,\n round(x::numeric) AS num_round,\n round(x::double precision) AS dbl_round\nFROM generate_series(-3.5, 3.5, 1) as x;\n x | num_round | dbl_round\n------+-----------+-----------\n -3.5 | -4 | -4\n -2.5 | -3 | -2\n -1.5 | -2 | -2\n -0.5 | -1 | -0\n 0.5 | 1 | 0\n 1.5 | 2 | 2\n 2.5 | 3 | 2\n 3.5 | 4 | 4\n(8 rows)\n</code>",
            "If you require exact storage and calculations (such as for monetary amounts), use the <code>numeric</code> type instead."
        ],
        "Storage Size": "variable",
        "Range": "up to 131072 digits before the decimal point; up to 16383 digits after the decimal point",
        "Tree": [
            "(numeric NUMERIC (opt_type_modifiers ( )))",
            "(numeric DECIMAL (opt_type_modifiers ( )))",
            "(numeric NUMERIC)",
            "(numeric DECIMAL)"
        ]
    },
    {
        "Type": [
            "integer",
            "int",
            "int4"
        ],
        "Description": [
            "signed four-byte integer",
            "typical choice for integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "\nThe types <code>smallint</code>, <code>integer</code>, and <code>bigint</code> store whole numbers, that is, numbers without fractional components, of various ranges. Attempts to store values outside of the allowed range will result in an error.\nThe type <code>integer</code> is the common choice, as it offers the best balance between range, storage size, and performance. The <code>smallint</code> type is generally only used if disk space is at a premium. The <code>bigint</code> type is designed to be used when the range of the <code>integer</code> type is insufficient.\nSQL only specifies the integer types <code>integer</code> (or <code>int</code>), <code>smallint</code>, and <code>bigint</code>. The type names <code>int2</code>, <code>int4</code>, and <code>int8</code> are extensions, which are also used by some other SQL database systems.\n",
            "<code>\nCREATE SEQUENCE tablename_colname_seq AS integer;\nCREATE TABLE tablename (\n colname integer NOT NULL DEFAULT nextval('tablename_colname_seq')\n);\nALTER SEQUENCE tablename_colname_seq OWNED BY tablename.colname;\n</code>",
            "The type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column."
        ],
        "Storage Size": "4 bytes",
        "Range": "-2147483648 to +2147483647",
        "Tree": [
            "(numeric INTEGER)",
            "(numeric INT)",
            "(identifier INT4)"
        ]
    },
    {
        "Type": [
            "real",
            "float4"
        ],
        "Description": [
            "single precision floating-point number (4 bytes)",
            "variable-precision, inexact"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "When rounding values, the <code>numeric</code> type rounds ties away from zero, while (on most machines) the <code>real</code> and <code>double precision</code> types round ties to the nearest even number. For example:",
            "The data types <code>real</code> and <code>double precision</code> are inexact, variable-precision numeric types. On all currently supported platforms, these types are implementations of IEEE Standard 754 for Binary Floating-Point Arithmetic (single and double precision, respectively), to the extent that the underlying processor, operating system, and compiler support it.",
            "On all currently supported platforms, the <code>real</code> type has a range of around 1E-37 to 1E+37 with a precision of at least 6 decimal digits. The <code>double precision</code> type has a range of around 1E-307 to 1E+308 with a precision of at least 15 digits. Values that are too large or too small will cause an error. Rounding might take place if the precision of an input number is too high. Numbers too close to zero that are not representable as distinct from zero will cause an underflow error.",
            "By default, floating point values are output in text form in their shortest precise decimal representation; the decimal value produced is closer to the true stored binary value than to any other value representable in the same binary precision. (However, the output value is currently never exactly midway between two representable values, in order to avoid a widespread bug where input routines do not properly respect the round-to-nearest-even rule.) This value will use at most 17 significant decimal digits for <code>float8</code> values, and at most 9 digits for <code>float4</code> values.",
            "For compatibility with output generated by older versions of PostgreSQL, and to allow the output precision to be reduced, the extra_float_digits parameter can be used to select rounded decimal output instead. Setting a value of 0 restores the previous default of rounding the value to 6 (for <code>float4</code>) or 15 (for <code>float8</code>) significant decimal digits. Setting a negative value reduces the number of digits further; for example -2 would round output to 4 or 13 digits respectively.",
            "PostgreSQL also supports the SQL-standard notations <code>float</code> and <code>float(p)</code> for specifying inexact numeric types. Here, <code>p</code> specifies the minimum acceptable precision in binary digits. PostgreSQL accepts <code>float(1)</code> to <code>float(24)</code> as selecting the <code>real</code> type, while <code>float(25)</code> to <code>float(53)</code> select <code>double precision</code>. Values of <code>p</code> outside the allowed range draw an error. <code>float</code> with no precision specified is taken to mean <code>double precision</code>."
        ],
        "Storage Size": "4 bytes",
        "Range": "6 decimal digits precision",
        "Tree": [
            "(numeric REAL)",
            "(identifier FLOAT4)"
        ]
    },
    {
        "Type": [
            "double precision",
            "float8"
        ],
        "Description": [
            "double precision floating-point number (8 bytes)",
            "variable-precision, inexact"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "When rounding values, the <code>numeric</code> type rounds ties away from zero, while (on most machines) the <code>real</code> and <code>double precision</code> types round ties to the nearest even number. For example:",
            "<code>\nSELECT x,\n round(x::numeric) AS num_round,\n round(x::double precision) AS dbl_round\nFROM generate_series(-3.5, 3.5, 1) as x;\n x | num_round | dbl_round\n------+-----------+-----------\n -3.5 | -4 | -4\n -2.5 | -3 | -2\n -1.5 | -2 | -2\n -0.5 | -1 | -0\n 0.5 | 1 | 0\n 1.5 | 2 | 2\n 2.5 | 3 | 2\n 3.5 | 4 | 4\n(8 rows)\n</code>",
            "The data types <code>real</code> and <code>double precision</code> are inexact, variable-precision numeric types. On all currently supported platforms, these types are implementations of IEEE Standard 754 for Binary Floating-Point Arithmetic (single and double precision, respectively), to the extent that the underlying processor, operating system, and compiler support it.",
            "On all currently supported platforms, the <code>real</code> type has a range of around 1E-37 to 1E+37 with a precision of at least 6 decimal digits. The <code>double precision</code> type has a range of around 1E-307 to 1E+308 with a precision of at least 15 digits. Values that are too large or too small will cause an error. Rounding might take place if the precision of an input number is too high. Numbers too close to zero that are not representable as distinct from zero will cause an underflow error.",
            "By default, floating point values are output in text form in their shortest precise decimal representation; the decimal value produced is closer to the true stored binary value than to any other value representable in the same binary precision. (However, the output value is currently never exactly midway between two representable values, in order to avoid a widespread bug where input routines do not properly respect the round-to-nearest-even rule.) This value will use at most 17 significant decimal digits for <code>float8</code> values, and at most 9 digits for <code>float4</code> values.",
            "For compatibility with output generated by older versions of PostgreSQL, and to allow the output precision to be reduced, the extra_float_digits parameter can be used to select rounded decimal output instead. Setting a value of 0 restores the previous default of rounding the value to 6 (for <code>float4</code>) or 15 (for <code>float8</code>) significant decimal digits. Setting a negative value reduces the number of digits further; for example -2 would round output to 4 or 13 digits respectively.",
            "PostgreSQL also supports the SQL-standard notations <code>float</code> and <code>float(p)</code> for specifying inexact numeric types. Here, <code>p</code> specifies the minimum acceptable precision in binary digits. PostgreSQL accepts <code>float(1)</code> to <code>float(24)</code> as selecting the <code>real</code> type, while <code>float(25)</code> to <code>float(53)</code> select <code>double precision</code>. Values of <code>p</code> outside the allowed range draw an error. <code>float</code> with no precision specified is taken to mean <code>double precision</code>."
        ],
        "Storage Size": "8 bytes",
        "Range": "15 decimal digits precision",
        "Tree": [
            "(numeric DOUBLE PRECISION)",
            "(identifier FLOAT8)"
        ]
    },
    {
        "Type": [
            "smallserial",
            "serial2"
        ],
        "Description": [
            "autoincrementing two-byte integer",
            "small autoincrementing integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "The data types <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are not true types, but merely a notational convenience for creating unique identifier columns (similar to the <code>AUTO_INCREMENT</code> property supported by some other databases). In the current implementation, specifying:",
            "Because <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are implemented using sequences, there may be \"holes\" or gaps in the sequence of values which appears in the column, even if no rows are ever deleted. A value allocated from the sequence is still \"used up\" even if a row containing that value is never successfully inserted into the table column. This may happen, for example, if the inserting transaction rolls back. See <code>nextval()</code> in Section 9.16 for details.",
            "The type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column."
        ],
        "Storage Size": "2 bytes",
        "Range": "1 to 32767",
        "Tree": [
            "(identifier SMALLSERIAL)",
            "(identifier SERIAL2)"
        ]
    },
    {
        "Type": [
            "serial",
            "serial4"
        ],
        "Description": [
            "autoincrementing four-byte integer",
            "autoincrementing integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-numeric.html#DATATYPE-INT",
        "Compensate": [
            "\nNote\nThis section describes a PostgreSQL-specific way to create an autoincrementing column. Another way is to use the SQL-standard identity column feature, described at CREATE TABLE.\nThe data types <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are not true types, but merely a notational convenience for creating unique identifier columns (similar to the <code>AUTO_INCREMENT</code> property supported by some other databases). In the current implementation, specifying:\n<code>\nCREATE TABLE <code>tablename</code> (\n <code>colname</code> SERIAL\n);\n</code>\nis equivalent to specifying:\n<code>\nCREATE SEQUENCE <code>tablename</code>_<code>colname</code>_seq AS integer;\nCREATE TABLE <code>tablename</code> (\n <code>colname</code> integer NOT NULL DEFAULT nextval('<code>tablename</code>_<code>colname</code>_seq')\n);\nALTER SEQUENCE <code>tablename</code>_<code>colname</code>_seq OWNED BY <code>tablename</code>.<code>colname</code>;\n</code>\nThus, we have created an integer column and arranged for its default values to be assigned from a sequence generator. A <code>NOT NULL</code> constraint is applied to ensure that a null value cannot be inserted. (In most cases you would also want to attach a <code>UNIQUE</code> or <code>PRIMARY KEY</code> constraint to prevent duplicate values from being inserted by accident, but this is not automatic.) Lastly, the sequence is marked as \"owned by\" the column, so that it will be dropped if the column or table is dropped.\nNote\nBecause <code>smallserial</code>, <code>serial</code> and <code>bigserial</code> are implemented using sequences, there may be \"holes\" or gaps in the sequence of values which appears in the column, even if no rows are ever deleted. A value allocated from the sequence is still \"used up\" even if a row containing that value is never successfully inserted into the table column. This may happen, for example, if the inserting transaction rolls back. See <code>nextval()</code> in Section 9.16 for details.\nTo insert the next value of the sequence into the <code>serial</code> column, specify that the <code>serial</code> column should be assigned its default value. This can be done either by excluding the column from the list of columns in the <code>INSERT</code> statement, or through the use of the <code>DEFAULT</code> key word.\nThe type names <code>serial</code> and <code>serial4</code> are equivalent: both create <code>integer</code> columns. The type names <code>bigserial</code> and <code>serial8</code> work the same way, except that they create a <code>bigint</code> column. <code>bigserial</code> should be used if you anticipate the use of more than 231 identifiers over the lifetime of the table. The type names <code>smallserial</code> and <code>serial2</code> also work the same way, except that they create a <code>smallint</code> column.\nThe sequence created for a <code>serial</code> column is automatically dropped when the owning column is dropped. You can drop the sequence without dropping the column, but this will force removal of the column default expression.\n"
        ],
        "Storage Size": "8 bytes",
        "Range": "1 to 9223372036854775807",
        "Tree": [
            "(identifier SERIAL)",
            "(identifier SERIAL4)"
        ]
    },
    {
        "Type": [
            "money"
        ],
        "Description": [
            "currency amount"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-money.html",
        "Compensate": [
            "The <code>money</code> type stores a currency amount with a fixed fractional precision; see Table 8.3. The fractional precision is determined by the database's lc_monetary setting. The range shown in the table assumes there are two fractional digits. Input is accepted in a variety of formats, including integer and floating-point literals, as well as typical currency formatting, such as <code>'$1,000.00'</code>. Output is generally in the latter form but depends on the locale.",
            "Since the output of this data type is locale-sensitive, it might not work to load <code>money</code> data into a database that has a different setting of <code>lc_monetary</code>. To avoid problems, before restoring a dump into a new database make sure <code>lc_monetary</code> has the same or equivalent value as in the database that was dumped.",
            "Values of the <code>numeric</code>, <code>int</code>, and <code>bigint</code> data types can be cast to <code>money</code>. Conversion from the <code>real</code> and <code>double precision</code> data types can be done by casting to <code>numeric</code> first, for example:",
            "<code>\nSELECT '12.34'::float8::numeric::money;\n</code>",
            "A <code>money</code> value can be cast to <code>numeric</code> without loss of precision. Conversion to other types could potentially lose precision, and must also be done in two stages:",
            "<code>\nSELECT '52093.89'::money::numeric::float8;\n</code>",
            "Division of a <code>money</code> value by an integer value is performed with truncation of the fractional part towards zero. To get a rounded result, divide by a floating-point value, or cast the <code>money</code> value to <code>numeric</code> before dividing and back to <code>money</code> afterwards. (The latter is preferable to avoid risking precision loss.) When a <code>money</code> value is divided by another <code>money</code> value, the result is <code>double precision</code> (i.e., a pure number, not money); the currency units cancel each other out in the division."
        ],
        "Storage Size": "8 bytes",
        "Range": "-92233720368547758.08 to +92233720368547758.07",
        "Tree": [
            "(identifier MONEY)"
        ]
    },
    {
        "Type": [
            "character varying ( n )",
            "varchar ( n )",
            "character varying",
            "varchar"
        ],
        "Description": [
            "variable-length character string",
            "variable-length with limit"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-character.html",
        "Compensate": [
            "SQL defines two primary character types: <code>character varying(n)</code> and <code>character(n)</code>, where <code>n</code> is a positive integer. Both of these types can store strings up to <code>n</code> characters (not bytes) in length. An attempt to store a longer string into a column of these types will result in an error, unless the excess characters are all spaces, in which case the string will be truncated to the maximum length. (This somewhat bizarre exception is required by the SQL standard.) If the string to be stored is shorter than the declared length, values of type <code>character</code> will be space-padded; values of type <code>character varying</code> will simply store the shorter string.",
            "If one explicitly casts a value to <code>character varying(n)</code> or <code>character(n)</code>, then an over-length value will be truncated to <code>n</code> characters without raising an error. (This too is required by the SQL standard.)",
            "The notations <code>varchar(n)</code> and <code>char(n)</code> are aliases for <code>character varying(n)</code> and <code>character(n)</code>, respectively. If specified, the length must be greater than zero and cannot exceed 10485760. <code>character</code> without length specifier is equivalent to <code>character(1)</code>. If <code>character varying</code> is used without length specifier, the type accepts strings of any size. The latter is a PostgreSQL extension.",
            "Values of type <code>character</code> are physically padded with spaces to the specified width <code>n</code>, and are stored and displayed that way. However, trailing spaces are treated as semantically insignificant and disregarded when comparing two values of type <code>character</code>. In collations where whitespace is significant, this behavior can produce unexpected results; for example <code>SELECT 'a '::CHAR(2) collate \"C\" < E'a\\n'::CHAR(2)</code> returns true, even though <code>C</code> locale would consider a space to be greater than a newline. Trailing spaces are removed when converting a <code>character</code> value to one of the other string types. Note that trailing spaces are semantically significant in <code>character varying</code> and <code>text</code> values, and when using pattern matching, that is <code>LIKE</code> and regular expressions.",
            "The storage requirement for a short string (up to 126 bytes) is 1 byte plus the actual string, which includes the space padding in the case of <code>character</code>. Longer strings have 4 bytes of overhead instead of 1. Long strings are compressed by the system automatically, so the physical requirement on disk might be less. Very long values are also stored in background tables so that they do not interfere with rapid access to shorter column values. In any case, the longest possible character string that can be stored is about 1 GB. (The maximum value that will be allowed for <code>n</code> in the data type declaration is less than that. It wouldn't be useful to change this because with multibyte character encodings the number of characters and bytes can be quite different. If you desire to store long strings with no specific upper limit, use <code>text</code> or <code>character varying</code> without a length specifier, rather than making up an arbitrary length limit.)",
            "There is no performance difference among these three types, apart from increased storage space when using the blank-padded type, and a few extra CPU cycles to check the length when storing into a length-constrained column. While <code>character(n)</code> has performance advantages in some other database systems, there is no such advantage in PostgreSQL; in fact <code>character(n)</code> is usually the slowest of the three because of its additional storage costs. In most situations <code>text</code> or <code>character varying</code> should be used instead.",
            "<code>\nCREATE TABLE test1 (a character(4));\nINSERT INTO test1 VALUES ('ok');\nSELECT a, char_length(a) FROM test1; -- (1)\n a | char_length\n------+-------------\n ok | 2\nCREATE TABLE test2 (b varchar(5));\nINSERT INTO test2 VALUES ('ok');\nINSERT INTO test2 VALUES ('good ');\nINSERT INTO test2 VALUES ('too long');\nERROR: value too long for type character varying(5)\nINSERT INTO test2 VALUES ('too long'::varchar(5)); -- explicit truncation\nSELECT b, char_length(b) FROM test2;\n b | char_length\n-------+-------------\n ok | 2\n good | 5\n too l | 5\n</code>"
        ],
        "Tree": [
            "(character (character_c CHARACTER (opt_varying VARYING)) ( ))",
            "(character (character_c VARCHAR) ( ))",
            "(character_c CHARACTER (opt_varying VARYING))",
            "(character_c VARCHAR)"
        ]
    },
    {
        "Type": [
            "character ( n )",
            "char ( n )",
            "character",
            "char"
        ],
        "Description": [
            "fixed-length character string",
            "fixed-length, blank padded"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-character.html",
        "Compensate": [
            "SQL defines two primary character types: <code>character varying(n)</code> and <code>character(n)</code>, where <code>n</code> is a positive integer. Both of these types can store strings up to <code>n</code> characters (not bytes) in length. An attempt to store a longer string into a column of these types will result in an error, unless the excess characters are all spaces, in which case the string will be truncated to the maximum length. (This somewhat bizarre exception is required by the SQL standard.) If the string to be stored is shorter than the declared length, values of type <code>character</code> will be space-padded; values of type <code>character varying</code> will simply store the shorter string.",
            "If one explicitly casts a value to <code>character varying(n)</code> or <code>character(n)</code>, then an over-length value will be truncated to <code>n</code> characters without raising an error. (This too is required by the SQL standard.)",
            "The notations <code>varchar(n)</code> and <code>char(n)</code> are aliases for <code>character varying(n)</code> and <code>character(n)</code>, respectively. If specified, the length must be greater than zero and cannot exceed 10485760. <code>character</code> without length specifier is equivalent to <code>character(1)</code>. If <code>character varying</code> is used without length specifier, the type accepts strings of any size. The latter is a PostgreSQL extension.",
            "Values of type <code>character</code> are physically padded with spaces to the specified width <code>n</code>, and are stored and displayed that way. However, trailing spaces are treated as semantically insignificant and disregarded when comparing two values of type <code>character</code>. In collations where whitespace is significant, this behavior can produce unexpected results; for example <code>SELECT 'a '::CHAR(2) collate \"C\" < E'a\\n'::CHAR(2)</code> returns true, even though <code>C</code> locale would consider a space to be greater than a newline. Trailing spaces are removed when converting a <code>character</code> value to one of the other string types. Note that trailing spaces are semantically significant in <code>character varying</code> and <code>text</code> values, and when using pattern matching, that is <code>LIKE</code> and regular expressions.",
            "The storage requirement for a short string (up to 126 bytes) is 1 byte plus the actual string, which includes the space padding in the case of <code>character</code>. Longer strings have 4 bytes of overhead instead of 1. Long strings are compressed by the system automatically, so the physical requirement on disk might be less. Very long values are also stored in background tables so that they do not interfere with rapid access to shorter column values. In any case, the longest possible character string that can be stored is about 1 GB. (The maximum value that will be allowed for <code>n</code> in the data type declaration is less than that. It wouldn't be useful to change this because with multibyte character encodings the number of characters and bytes can be quite different. If you desire to store long strings with no specific upper limit, use <code>text</code> or <code>character varying</code> without a length specifier, rather than making up an arbitrary length limit.)",
            "There is no performance difference among these three types, apart from increased storage space when using the blank-padded type, and a few extra CPU cycles to check the length when storing into a length-constrained column. While <code>character(n)</code> has performance advantages in some other database systems, there is no such advantage in PostgreSQL; in fact <code>character(n)</code> is usually the slowest of the three because of its additional storage costs. In most situations <code>text</code> or <code>character varying</code> should be used instead.",
            "<code>\nCREATE TABLE test1 (a character(4));\nINSERT INTO test1 VALUES ('ok');\nSELECT a, char_length(a) FROM test1; -- (1)\n a | char_length\n------+-------------\n ok | 2\nCREATE TABLE test2 (b varchar(5));\nINSERT INTO test2 VALUES ('ok');\nINSERT INTO test2 VALUES ('good ');\nINSERT INTO test2 VALUES ('too long');\nERROR: value too long for type character varying(5)\nINSERT INTO test2 VALUES ('too long'::varchar(5)); -- explicit truncation\nSELECT b, char_length(b) FROM test2;\n b | char_length\n-------+-------------\n ok | 2\n good | 5\n too l | 5\n</code>",
            "The <code>char_length</code> function is discussed in Section 9.4.",
            "There are two other fixed-length character types in PostgreSQL, shown in Table 8.5. The <code>name</code> type exists only for the storage of identifiers in the internal system catalogs and is not intended for use by the general user. Its length is currently defined as 64 bytes (63 usable characters plus terminator) but should be referenced using the constant <code>NAMEDATALEN</code> in <code>C</code> source code. The length is set at compile time (and is therefore adjustable for special uses); the default maximum length might change in a future release. The type <code>\"char\"</code> (note the quotes) is different from <code>char(1)</code> in that it only uses one byte of storage. It is internally used in the system catalogs as a simplistic enumeration type."
        ],
        "Storage Size": "1 byte",
        "Tree": [
            "(character (character_c CHARACTER) ( ))",
            "(character (character_c CHAR) ( ))",
            "(character_c CHARACTER)",
            "(character_c CHAR)"
        ]
    },
    {
        "Type": [
            "text"
        ],
        "Description": [
            "variable-length character string",
            "variable unlimited length"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-character.html",
        "Compensate": [
            "In addition, PostgreSQL provides the <code>text</code> type, which stores strings of any length. Although the type <code>text</code> is not in the SQL standard, several other SQL database management systems have it as well.",
            "Values of type <code>character</code> are physically padded with spaces to the specified width <code>n</code>, and are stored and displayed that way. However, trailing spaces are treated as semantically insignificant and disregarded when comparing two values of type <code>character</code>. In collations where whitespace is significant, this behavior can produce unexpected results; for example <code>SELECT 'a '::CHAR(2) collate \"C\" < E'a\\n'::CHAR(2)</code> returns true, even though <code>C</code> locale would consider a space to be greater than a newline. Trailing spaces are removed when converting a <code>character</code> value to one of the other string types. Note that trailing spaces are semantically significant in <code>character varying</code> and <code>text</code> values, and when using pattern matching, that is <code>LIKE</code> and regular expressions.",
            "The storage requirement for a short string (up to 126 bytes) is 1 byte plus the actual string, which includes the space padding in the case of <code>character</code>. Longer strings have 4 bytes of overhead instead of 1. Long strings are compressed by the system automatically, so the physical requirement on disk might be less. Very long values are also stored in background tables so that they do not interfere with rapid access to shorter column values. In any case, the longest possible character string that can be stored is about 1 GB. (The maximum value that will be allowed for <code>n</code> in the data type declaration is less than that. It wouldn't be useful to change this because with multibyte character encodings the number of characters and bytes can be quite different. If you desire to store long strings with no specific upper limit, use <code>text</code> or <code>character varying</code> without a length specifier, rather than making up an arbitrary length limit.)",
            "There is no performance difference among these three types, apart from increased storage space when using the blank-padded type, and a few extra CPU cycles to check the length when storing into a length-constrained column. While <code>character(n)</code> has performance advantages in some other database systems, there is no such advantage in PostgreSQL; in fact <code>character(n)</code> is usually the slowest of the three because of its additional storage costs. In most situations <code>text</code> or <code>character varying</code> should be used instead."
        ],
        "Tree": [
            "(unreserved_keyword TEXT)"
        ]
    },
    {
        "Type": [
            "bytea"
        ],
        "Description": [
            "binary data (\"byte array\")",
            "variable-length binary string"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-binary.html",
        "Compensate": [
            "The <code>bytea</code> data type allows storage of binary strings; see Table 8.6.",
            "The <code>bytea</code> type supports two formats for input and output: \"hex\" format and PostgreSQL's historical \"escape\" format. Both of these are always accepted on input. The output format depends on the configuration parameter bytea_output; the default is hex. (Note that the hex format was introduced in PostgreSQL 9.0; earlier versions and some tools don't understand it.)",
            "The SQL standard defines a different binary string type, called <code>BLOB</code> or <code>BINARY LARGE OBJECT</code>. The input format is different from <code>bytea</code>, but the provided functions and operators are mostly the same.",
            "\nThe \"hex\" format encodes binary data as 2 hexadecimal digits per byte, most significant nibble first. The entire string is preceded by the sequence <code>\\x</code> (to distinguish it from the escape format). In some contexts, the initial backslash may need to be escaped by doubling it (see Section 4.1.2.1). For input, the hexadecimal digits can be either upper or lower case, and whitespace is permitted between digit pairs (but not within a digit pair nor in the starting <code>\\x</code> sequence). The hex format is compatible with a wide range of external applications and protocols, and it tends to be faster to convert than the escape format, so its use is preferred.\nExample:\n<code>\nSET bytea_output = 'hex';\nSELECT '\\xDEADBEEF'::bytea;\n bytea\n------------\n \\xdeadbeef\n</code>\n",
            "\nThe \"escape\" format is the traditional PostgreSQL format for the <code>bytea</code> type. It takes the approach of representing a binary string as a sequence of ASCII characters, while converting those bytes that cannot be represented as an ASCII character into special escape sequences. If, from the point of view of the application, representing bytes as characters makes sense, then this representation can be convenient. But in practice it is usually confusing because it fuzzes up the distinction between binary strings and character strings, and also the particular escape mechanism that was chosen is somewhat unwieldy. Therefore, this format should probably be avoided for most new applications.\nWhen entering <code>bytea</code> values in escape format, octets of certain values must be escaped, while all octet values can be escaped. In general, to escape an octet, convert it into its three-digit octal value and precede it by a backslash. Backslash itself (octet decimal value 92) can alternatively be represented by double backslashes. Table 8.7 shows the characters that must be escaped, and gives the alternative escape sequences where applicable.\nTable 8.7. <code>bytea</code> Literal Escaped Octets\n<table>\n<thead>\n<tr>\n<th>Decimal Octet Value</th>\n<th>Description</th>\n<th>Escaped Input Representation</th>\n<th>Example</th>\n<th>Hex Representation</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>0</td>\n<td>zero octet</td>\n<td><code>'\\000'</code></td>\n<td><code>SELECT '\\000'::bytea;</code></td>\n<td><code>\\x00</code></td>\n</tr>\n<tr>\n<td>39</td>\n<td>single quote</td>\n<td><code>''''</code> or <code>'\\047'</code></td>\n<td><code>SELECT ''''::bytea;</code></td>\n<td><code>\\x27</code></td>\n</tr>\n<tr>\n<td>92</td>\n<td>backslash</td>\n<td><code>'\\\\'</code> or <code>'\\134'</code></td>\n<td><code>SELECT '\\\\'::bytea;</code></td>\n<td><code>\\x5c</code></td>\n</tr>\n<tr>\n<td>0 to 31 and 127 to 255</td>\n<td>\"non-printable\" octets</td>\n<td><code>'\\xxx'</code> (octal value)</td>\n<td><code>SELECT '\\001'::bytea;</code></td>\n<td><code>\\x01</code></td>\n</tr>\n</tbody>\n</table>\nThe requirement to escape non-printable octets varies depending on locale settings. In some instances you can get away with leaving them unescaped.\nThe reason that single quotes must be doubled, as shown in Table 8.7, is that this is true for any string literal in a SQL command. The generic string-literal parser consumes the outermost single quotes and reduces any pair of single quotes to one data character. What the <code>bytea</code> input function sees is just one single quote, which it treats as a plain data character. However, the <code>bytea</code> input function treats backslashes as special, and the other behaviors shown in Table 8.7 are implemented by that function.\nIn some contexts, backslashes must be doubled compared to what is shown above, because the generic string-literal parser will also reduce pairs of backslashes to one data character; see Section 4.1.2.1.\n<code>Bytea</code> octets are output in <code>hex</code> format by default. If you change bytea_output to <code>escape</code>, \"non-printable\" octets are converted to their equivalent three-digit octal value and preceded by one backslash. Most \"printable\" octets are output by their standard representation in the client character set, e.g.:\n<code>\nSET bytea_output = 'escape';\nSELECT 'abc \\153\\154\\155 \\052\\251\\124'::bytea;\n bytea\n----------------\n abc klm *\\251T\n</code>\nThe octet with decimal value 92 (backslash) is doubled in the output. Details are in Table 8.8.\nTable 8.8. <code>bytea</code> Output Escaped Octets\n<table>\n<thead>\n<tr>\n<th>Decimal Octet Value</th>\n<th>Description</th>\n<th>Escaped Output Representation</th>\n<th>Example</th>\n<th>Output Result</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>92</td>\n<td>backslash</td>\n<td><code>\\\\</code></td>\n<td><code>SELECT '\\134'::bytea;</code></td>\n<td><code>\\\\</code></td>\n</tr>\n<tr>\n<td>0 to 31 and 127 to 255</td>\n<td>\"non-printable\" octets</td>\n<td><code>\\xxx</code> (octal value)</td>\n<td><code>SELECT '\\001'::bytea;</code></td>\n<td><code>\\001</code></td>\n</tr>\n<tr>\n<td>32 to 126</td>\n<td>\"printable\" octets</td>\n<td>client character set representation</td>\n<td><code>SELECT '\\176'::bytea;</code></td>\n<td><code>~</code></td>\n</tr>\n</tbody>\n</table>\nDepending on the front end to PostgreSQL you use, you might have additional work to do in terms of escaping and unescaping <code>bytea</code> strings. For example, you might also have to escape line feeds and carriage returns if your interface automatically translates these.\n"
        ],
        "Storage Size": "1 or 4 bytes plus the actual binary string",
        "Tree": [
            "(identifier BYTEA)"
        ]
    },
    {
        "Type": [
            "timestamp ( p )",
            "timestamp ( p ) without time zone",
            "timestamp",
            "timestamp without time zone"
        ],
        "Description": [
            "date and time (no time zone)",
            "both date and time (no time zone)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "The SQL standard requires that writing just <code>timestamp</code> be equivalent to <code>timestamp without time zone</code>, and PostgreSQL honors that behavior. <code>timestamptz</code> is accepted as an abbreviation for <code>timestamp with time zone</code>; this is a PostgreSQL extension.",
            "<code>time</code>, <code>timestamp</code>, and <code>interval</code> accept an optional precision value <code>p</code> which specifies the number of fractional digits retained in the seconds field. By default, there is no explicit bound on precision. The allowed range of <code>p</code> is from 0 to 6.",
            "The type <code>time with time zone</code> is defined by the SQL standard, but the definition exhibits properties which lead to questionable usefulness. In most cases, a combination of <code>date</code>, <code>time</code>, <code>timestamp without time zone</code>, and <code>timestamp with time zone</code> should provide a complete range of date/time functionality required by any application.",
            "where <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).",
            "The SQL standard differentiates <code>timestamp without time zone</code> and <code>timestamp with time zone</code> literals by the presence of a \"+\" or \"-\" symbol and time zone offset after the time. Hence, according to the standard,",
            "<code>TIMESTAMP '2004-10-19 10:23:54'</code>",
            "is a <code>timestamp without time zone</code>, while",
            "<code>TIMESTAMP '2004-10-19 10:23:54+02'</code>",
            "is a <code>timestamp with time zone</code>. PostgreSQL never examines the content of a literal string before determining its type, and therefore will treat both of the above as <code>timestamp without time zone</code>. To ensure that a literal is treated as <code>timestamp with time zone</code>, give it the correct explicit type:",
            "<code>TIMESTAMP WITH TIME ZONE '2004-10-19 10:23:54+02'</code>",
            "In a literal that has been determined to be <code>timestamp without time zone</code>, PostgreSQL will silently ignore any time zone indication. That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.",
            "For <code>timestamp with time zone</code>, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system's TimeZone parameter, and is converted to UTC using the offset for the <code>timezone</code> zone.",
            "When a <code>timestamp with time zone</code> value is output, it is always converted from UTC to the current <code>timezone</code> zone, and displayed as local time in that zone. To see the time in another time zone, either change <code>timezone</code> or use the <code>AT TIME ZONE</code> construct (see Section 9.9.3).",
            "Conversions between <code>timestamp without time zone</code> and <code>timestamp with time zone</code> normally assume that the <code>timestamp without time zone</code> value should be taken or given as <code>timezone</code> local time. A different time zone can be specified for the conversion using <code>AT TIME ZONE</code>.",
            "The following SQL-compatible functions can also be used to obtain the current time value for the corresponding data type: <code>CURRENT_DATE</code>, <code>CURRENT_TIME</code>, <code>CURRENT_TIMESTAMP</code>, <code>LOCALTIME</code>, <code>LOCALTIMESTAMP</code>. (See Section 9.9.4.) Note that these are SQL functions and are not recognized in data input strings.",
            "Internally <code>interval</code> values are stored as months, days, and microseconds. This is done because the number of days in a month varies, and a day can have 23 or 25 hours if a daylight savings time adjustment is involved. The months and days fields are integers while the microseconds field can store fractional seconds. Because intervals are usually created from constant strings or <code>timestamp</code> subtraction, this storage method works well in most cases, but can cause unexpected results:"
        ],
        "Storage Size": "8 bytes",
        "Low Value": "4713 BC",
        "High Value": "294276 AD",
        "Resolution": "1 microsecond",
        "Tree": [
            "(constdatetime TIMESTAMP ( ))",
            "(constdatetime TIMESTAMP ( ) (opt_timezone WITHOUT TIME ZONE))",
            "(constdatetime TIMESTAMP)",
            "(constdatetime TIMESTAMP (opt_timezone WITHOUT TIME ZONE))"
        ]
    },
    {
        "Type": [
            "timestamp ( p ) with time zone",
            "timestamp with time zone",
            "timestamptz"
        ],
        "Description": [
            "date and time, including time zone",
            "both date and time, with time zone"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "The SQL standard requires that writing just <code>timestamp</code> be equivalent to <code>timestamp without time zone</code>, and PostgreSQL honors that behavior. <code>timestamptz</code> is accepted as an abbreviation for <code>timestamp with time zone</code>; this is a PostgreSQL extension.",
            "<code>time</code>, <code>timestamp</code>, and <code>interval</code> accept an optional precision value <code>p</code> which specifies the number of fractional digits retained in the seconds field. By default, there is no explicit bound on precision. The allowed range of <code>p</code> is from 0 to 6.",
            "The type <code>time with time zone</code> is defined by the SQL standard, but the definition exhibits properties which lead to questionable usefulness. In most cases, a combination of <code>date</code>, <code>time</code>, <code>timestamp without time zone</code>, and <code>timestamp with time zone</code> should provide a complete range of date/time functionality required by any application.",
            "where <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).",
            "The SQL standard differentiates <code>timestamp without time zone</code> and <code>timestamp with time zone</code> literals by the presence of a \"+\" or \"-\" symbol and time zone offset after the time. Hence, according to the standard,",
            "<code>TIMESTAMP '2004-10-19 10:23:54'</code>",
            "is a <code>timestamp without time zone</code>, while",
            "<code>TIMESTAMP '2004-10-19 10:23:54+02'</code>",
            "is a <code>timestamp with time zone</code>. PostgreSQL never examines the content of a literal string before determining its type, and therefore will treat both of the above as <code>timestamp without time zone</code>. To ensure that a literal is treated as <code>timestamp with time zone</code>, give it the correct explicit type:",
            "<code>TIMESTAMP WITH TIME ZONE '2004-10-19 10:23:54+02'</code>",
            "In a literal that has been determined to be <code>timestamp without time zone</code>, PostgreSQL will silently ignore any time zone indication. That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.",
            "For <code>timestamp with time zone</code>, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system's TimeZone parameter, and is converted to UTC using the offset for the <code>timezone</code> zone.",
            "When a <code>timestamp with time zone</code> value is output, it is always converted from UTC to the current <code>timezone</code> zone, and displayed as local time in that zone. To see the time in another time zone, either change <code>timezone</code> or use the <code>AT TIME ZONE</code> construct (see Section 9.9.3).",
            "Conversions between <code>timestamp without time zone</code> and <code>timestamp with time zone</code> normally assume that the <code>timestamp without time zone</code> value should be taken or given as <code>timezone</code> local time. A different time zone can be specified for the conversion using <code>AT TIME ZONE</code>.",
            "The following SQL-compatible functions can also be used to obtain the current time value for the corresponding data type: <code>CURRENT_DATE</code>, <code>CURRENT_TIME</code>, <code>CURRENT_TIMESTAMP</code>, <code>LOCALTIME</code>, <code>LOCALTIMESTAMP</code>. (See Section 9.9.4.) Note that these are SQL functions and are not recognized in data input strings.",
            "Internally <code>interval</code> values are stored as months, days, and microseconds. This is done because the number of days in a month varies, and a day can have 23 or 25 hours if a daylight savings time adjustment is involved. The months and days fields are integers while the microseconds field can store fractional seconds. Because intervals are usually created from constant strings or <code>timestamp</code> subtraction, this storage method works well in most cases, but can cause unexpected results:"
        ],
        "Storage Size": "8 bytes",
        "Low Value": "4713 BC",
        "High Value": "294276 AD",
        "Resolution": "1 microsecond",
        "Tree": [
            "(constdatetime TIMESTAMP ( ) (opt_timezone WITH TIME ZONE))",
            "(constdatetime TIMESTAMP (opt_timezone WITH TIME ZONE))",
            "(identifier TIMESTAMPTZ)"
        ]
    },
    {
        "Type": [
            "time ( p ) without time zone",
            "time without time zone",
            "time ( p )",
            "time"
        ],
        "Description": [
            "time of day (no time zone)",
            "time of day (no date)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "<code>time</code>, <code>timestamp</code>, and <code>interval</code> accept an optional precision value <code>p</code> which specifies the number of fractional digits retained in the seconds field. By default, there is no explicit bound on precision. The allowed range of <code>p</code> is from 0 to 6.",
            "The type <code>time with time zone</code> is defined by the SQL standard, but the definition exhibits properties which lead to questionable usefulness. In most cases, a combination of <code>date</code>, time, <code>timestamp without time zone</code>, and <code>timestamp with time zone</code> should provide a complete range of date/time functionality required by any application.",
            "\nDate and time input is accepted in almost any reasonable format, including ISO 8601, SQL-compatible, traditional POSTGRES, and others. For some formats, ordering of day, month, and year in date input is ambiguous and there is support for specifying the expected ordering of these fields. Set the DateStyle parameter to <code>MDY</code> to select month-day-year interpretation, <code>DMY</code> to select day-month-year interpretation, or <code>YMD</code> to select year-month-day interpretation.\nPostgreSQL is more flexible in handling date/time input than the SQL standard requires. See Appendix B for the exact parsing rules of date/time input and for the recognized text fields including months, days of the week, and time zones.\nRemember that any date or time literal input needs to be enclosed in single quotes, like text strings. Refer to Section 4.1.2.7 for more information. SQL requires the following syntax\n<code>\n<code>type</code> [ (<code>p</code>) ] '<code>value</code>'\n</code>\nwhere <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).\n8.5.1.1. Dates\nTable 8.10 shows some possible inputs for the <code>date</code> type.\nTable 8.10. Date Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1999-01-08</td>\n<td>ISO 8601; January 8 in any mode (recommended format)</td>\n</tr>\n<tr>\n<td>January 8, 1999</td>\n<td>unambiguous in any <code>datestyle</code> input mode</td>\n</tr>\n<tr>\n<td>1/8/1999</td>\n<td>January 8 in <code>MDY</code> mode; August 1 in <code>DMY</code> mode</td>\n</tr>\n<tr>\n<td>1/18/1999</td>\n<td>January 18 in <code>MDY</code> mode; rejected in other modes</td>\n</tr>\n<tr>\n<td>01/02/03</td>\n<td>January 2, 2003 in <code>MDY</code> mode; February 1, 2003 in <code>DMY</code> mode; February 3, 2001 in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>1999-Jan-08</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>Jan-08-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>08-Jan-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>99-Jan-08</td>\n<td>January 8 in <code>YMD</code> mode, else error</td>\n</tr>\n<tr>\n<td>08-Jan-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>Jan-08-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>19990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>1999.008</td>\n<td>year and day of year</td>\n</tr>\n<tr>\n<td>J2451187</td>\n<td>Julian date</td>\n</tr>\n<tr>\n<td>January 8, 99 BC</td>\n<td>year 99 BC</td>\n</tr>\n</tbody>\n</table>\n8.5.1.2. Times\nThe time-of-day types are <code>time [ (p) ] without time zone</code> and <code>time [ (p) ] with time zone</code>. <code>time</code> alone is equivalent to <code>time without time zone</code>.\nValid input for these types consists of a time of day followed by an optional time zone. (See Table 8.11 and Table 8.12.) If a time zone is specified in the input for <code>time without time zone</code>, it is silently ignored. You can also specify a date but it will be ignored, except when you use a time zone name that involves a daylight-savings rule, such as <code>America/New_York</code>. In this case specifying the date is required in order to determine whether standard or daylight-savings time applies. The appropriate time zone offset is recorded in the <code>time with time zone</code> value and is output as stored; it is not adjusted to the active time zone.\nTable 8.11. Time Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>04:05:06.789</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05:06</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>040506</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05 AM</code></td>\n<td>same as 04:05; AM does not affect value</td>\n</tr>\n<tr>\n<td><code>04:05 PM</code></td>\n<td>same as 16:05; input hour must be <= 12</td>\n</tr>\n<tr>\n<td><code>04:05:06.789-8</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05:06-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506-08</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+0730</code></td>\n<td>ISO 8601, with fractional-hour time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+07:30:00</code></td>\n<td>UTC offset specified to seconds (not allowed in ISO 8601)</td>\n</tr>\n<tr>\n<td><code>04:05:06 PST</code></td>\n<td>time zone specified by abbreviation</td>\n</tr>\n<tr>\n<td><code>2003-04-12 04:05:06 America/New_York</code></td>\n<td>time zone specified by full name</td>\n</tr>\n</tbody>\n</table>\nTable 8.12. Time Zone Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>PST</code></td>\n<td>Abbreviation (for Pacific Standard Time)</td>\n</tr>\n<tr>\n<td><code>America/New_York</code></td>\n<td>Full time zone name</td>\n</tr>\n<tr>\n<td><code>PST8PDT</code></td>\n<td>POSIX-style time zone specification</td>\n</tr>\n<tr>\n<td><code>-8:00:00</code></td>\n<td>UTC offset for PST</td>\n</tr>\n<tr>\n<td><code>-8:00</code></td>\n<td>UTC offset for PST (ISO 8601 extended format)</td>\n</tr>\n<tr>\n<td><code>-800</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>-8</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>zulu</code></td>\n<td>Military abbreviation for UTC</td>\n</tr>\n<tr>\n<td><code>z</code></td>\n<td>Short form of <code>zulu</code> (also in ISO 8601)</td>\n</tr>\n</tbody>\n</table>\nRefer to Section 8.5.3 for more information on how to specify time zones.\n8.5.1.3. Time Stamps\nValid input for the time stamp types consists of the concatenation of a date and a time, followed by an optional time zone, followed by an optional <code>AD</code> or <code>BC</code>. (Alternatively, <code>AD</code>/<code>BC</code> can appear before the time zone, but this is not the preferred ordering.) Thus:\n<code>\n1999-01-08 04:05:06\n</code>\nand:\n<code>\n1999-01-08 04:05:06 -8:00\n</code>\nare valid values, which follow the ISO 8601 standard. In addition, the common format:\n<code>\nJanuary 8 04:05:06 1999 PST\n</code>\nis supported.\nThe SQL standard differentiates <code>timestamp without time zone</code> and <code>timestamp with time zone</code> literals by the presence of a \"+\" or \"-\" symbol and time zone offset after the time. Hence, according to the standard,\n<code>TIMESTAMP '2004-10-19 10:23:54'</code>\nis a <code>timestamp without time zone</code>, while\n<code>TIMESTAMP '2004-10-19 10:23:54+02'</code>\nis a <code>timestamp with time zone</code>. PostgreSQL never examines the content of a literal string before determining its type, and therefore will treat both of the above as <code>timestamp without time zone</code>. To ensure that a literal is treated as <code>timestamp with time zone</code>, give it the correct explicit type:\n<code>TIMESTAMP WITH TIME ZONE '2004-10-19 10:23:54+02'</code>\nIn a literal that has been determined to be <code>timestamp without time zone</code>, PostgreSQL will silently ignore any time zone indication. That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.\nFor <code>timestamp with time zone</code>, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system's TimeZone parameter, and is converted to UTC using the offset for the <code>timezone</code> zone.\nWhen a <code>timestamp with time zone</code> value is output, it is always converted from UTC to the current <code>timezone</code> zone, and displayed as local time in that zone. To see the time in another time zone, either change <code>timezone</code> or use the <code>AT TIME ZONE</code> construct (see Section 9.9.3).\nConversions between <code>timestamp without time zone</code> and <code>timestamp with time zone</code> normally assume that the <code>timestamp without time zone</code> value should be taken or given as <code>timezone</code> local time. A different time zone can be specified for the conversion using <code>AT TIME ZONE</code>.\n8.5.1.4. Special Values\nPostgreSQL supports several special date/time input values for convenience, as shown in Table 8.13. The values <code>infinity</code> and <code>-infinity</code> are specially represented inside the system and will be displayed unchanged; but the others are simply notational shorthands that will be converted to ordinary date/time values when read. (In particular, <code>now</code> and related strings are converted to a specific time value as soon as they are read.) All of these values need to be enclosed in single quotes when used as constants in SQL commands.\nTable 8.13. Special Date/Time Inputs\n<table>\n<thead>\n<tr>\n<th>Input String</th>\n<th>Valid Types</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>epoch</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>1970-01-01 00:00:00+00 (Unix system time zero)</td>\n</tr>\n<tr>\n<td><code>infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>later than all other time stamps</td>\n</tr>\n<tr>\n<td><code>-infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>earlier than all other time stamps</td>\n</tr>\n<tr>\n<td><code>now</code></td>\n<td><code>date</code>, <code>time</code>, <code>timestamp</code></td>\n<td>current transaction's start time</td>\n</tr>\n<tr>\n<td><code>today</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) today</td>\n</tr>\n<tr>\n<td><code>tomorrow</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) tomorrow</td>\n</tr>\n<tr>\n<td><code>yesterday</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) yesterday</td>\n</tr>\n<tr>\n<td><code>allballs</code></td>\n<td><code>time</code></td>\n<td>00:00:00.00 UTC</td>\n</tr>\n</tbody>\n</table>\nThe following SQL-compatible functions can also be used to obtain the current time value for the corresponding data type: <code>CURRENT_DATE</code>, <code>CURRENT_TIME</code>, <code>CURRENT_TIMESTAMP</code>, <code>LOCALTIME</code>, <code>LOCALTIMESTAMP</code>. (See Section 9.9.4.) Note that these are SQL functions and are not recognized in data input strings.\nCaution\nWhile the input strings <code>now</code>, <code>today</code>, <code>tomorrow</code>, and <code>yesterday</code> are fine to use in interactive SQL commands, they can have surprising behavior when the command is saved to be executed later, for example in prepared statements, views, and function definitions. The string can be converted to a specific time value that continues to be used long after it becomes stale. Use one of the SQL functions instead in such contexts. For example, <code>CURRENT_DATE + 1</code> is safer than <code>'tomorrow'::date</code>.\n",
            "\nThe output format of the date/time types can be set to one of the four styles ISO 8601, SQL (Ingres), traditional POSTGRES (Unix date format), or German. The default is the ISO format. (The SQL standard requires the use of the ISO 8601 format. The name of the \"SQL\" output format is a historical accident.) Table 8.14 shows examples of each output style. The output of the <code>date</code> and <code>time</code> types is generally only the date or time part in accordance with the given examples. However, the POSTGRES style outputs date-only values in ISO format.\nTable 8.14. Date/Time Output Styles\n<table>\n<thead>\n<tr>\n<th>Style Specification</th>\n<th>Description</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ISO</code></td>\n<td>ISO 8601, SQL standard</td>\n<td><code>1997-12-17 07:37:16-08</code></td>\n</tr>\n<tr>\n<td><code>SQL</code></td>\n<td>traditional style</td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres</code></td>\n<td>original style</td>\n<td><code>Wed Dec 17 07:37:16 1997 PST</code></td>\n</tr>\n<tr>\n<td><code>German</code></td>\n<td>regional style</td>\n<td><code>17.12.1997 07:37:16.00 PST</code></td>\n</tr>\n</tbody>\n</table>\nNote\nISO 8601 specifies the use of uppercase letter <code>T</code> to separate the date and time. PostgreSQL accepts that format on input, but on output it uses a space rather than <code>T</code>, as shown above. This is for readability and for consistency with RFC 3339 as well as some other database systems.\nIn the SQL and POSTGRES styles, day appears before month if DMY field ordering has been specified, otherwise month appears before day. (See Section 8.5.1 for how this setting also affects interpretation of input values.) Table 8.15 shows examples.\nTable 8.15. Date Order Conventions\n<table>\n<thead>\n<tr>\n<th><code>datestyle</code> Setting</th>\n<th>Input Ordering</th>\n<th>Example Output</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>SQL, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>17/12/1997 15:37:16.00 CET</code></td>\n</tr>\n<tr>\n<td><code>SQL, MDY</code></td>\n<td><code>month</code>/<code>day</code>/<code>year</code></td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>Wed 17 Dec 07:37:16 1997 PST</code></td>\n</tr>\n</tbody>\n</table>\nIn the ISO style, the time zone is always shown as a signed numeric offset from UTC, with positive sign used for zones east of Greenwich. The offset will be shown as <code>hh</code> (hours only) if it is an integral number of hours, else as <code>hh</code>:<code>mm</code> if it is an integral number of minutes, else as <code>hh</code>:<code>mm</code>:<code>ss</code>. (The third case is not possible with any modern time zone standard, but it can appear when working with timestamps that predate the adoption of standardized time zones.) In the other date styles, the time zone is shown as an alphabetic abbreviation if one is in common use in the current zone. Otherwise it appears as a signed numeric offset in ISO 8601 basic format (<code>hh</code> or <code>hhmm</code>).\nThe date/time style can be selected by the user using the <code>SET datestyle</code> command, the DateStyle parameter in the <code>postgresql.conf</code> configuration file, or the <code>PGDATESTYLE</code> environment variable on the server or client.\nThe formatting function <code>to_char</code> (see Section 9.8) is also available as a more flexible way to format date/time output.\n",
            "\nTime zones, and time-zone conventions, are influenced by political decisions, not just earth geometry. Time zones around the world became somewhat standardized during the 1900s, but continue to be prone to arbitrary changes, particularly with respect to daylight-savings rules. PostgreSQL uses the widely-used IANA (Olson) time zone database for information about historical time zone rules. For times in the future, the assumption is that the latest known rules for a given time zone will continue to be observed indefinitely far into the future.\nPostgreSQL endeavors to be compatible with the SQL standard definitions for typical usage. However, the SQL standard has an odd mix of date and time types and capabilities. Two obvious problems are:\nAlthough the <code>date</code> type cannot have an associated time zone, the <code>time</code> type can. Time zones in the real world have little meaning unless associated with a date as well as a time, since the offset can vary through the year with daylight-saving time boundaries.\nThe default time zone is specified as a constant numeric offset from UTC. It is therefore impossible to adapt to daylight-saving time when doing date/time arithmetic across DST boundaries.\nTo address these difficulties, we recommend using date/time types that contain both date and time when using time zones. We do not recommend using the type <code>time with time zone</code> (though it is supported by PostgreSQL for legacy applications and for compliance with the SQL standard). PostgreSQL assumes your local time zone for any type containing only date or time.\nAll timezone-aware dates and times are stored internally in UTC. They are converted to local time in the zone specified by the TimeZone configuration parameter before being displayed to the client.\nPostgreSQL allows you to specify time zones in three different forms:\nA full time zone name, for example <code>America/New_York</code>. The recognized time zone names are listed in the <code>pg_timezone_names</code> view (see Section 51.92). PostgreSQL uses the widely-used IANA time zone data for this purpose, so the same time zone names are also recognized by other software.\nA time zone abbreviation, for example <code>PST</code>. Such a specification merely defines a particular offset from UTC, in contrast to full time zone names which can imply a set of daylight savings transition rules as well. The recognized abbreviations are listed in the <code>pg_timezone_abbrevs</code> view (see Section 51.91). You cannot set the configuration parameters TimeZone or log_timezone to a time zone abbreviation, but you can use abbreviations in date/time input values and with the <code>AT TIME ZONE</code> operator.\nIn addition to the timezone names and abbreviations, PostgreSQL will accept POSIX-style time zone specifications, as described in Section B.5. This option is not normally preferable to using a named time zone, but it may be necessary if no suitable IANA time zone entry is available.\nIn short, this is the difference between abbreviations and full names: abbreviations represent a specific offset from UTC, whereas many of the full names imply a local daylight-savings time rule, and so have two possible UTC offsets. As an example, <code>2014-06-04 12:00 America/New_York</code> represents noon local time in New York, which for this particular date was Eastern Daylight Time (UTC-4). So <code>2014-06-04 12:00 EDT</code> specifies that same time instant. But <code>2014-06-04 12:00 EST</code> specifies noon Eastern Standard Time (UTC-5), regardless of whether daylight savings was nominally in effect on that date.\nTo complicate matters, some jurisdictions have used the same timezone abbreviation to mean different UTC offsets at different times; for example, in Moscow <code>MSK</code> has meant UTC+3 in some years and UTC+4 in others. PostgreSQL interprets such abbreviations according to whatever they meant (or had most recently meant) on the specified date; but, as with the <code>EST</code> example above, this is not necessarily the same as local civil time on that date.\nIn all cases, timezone names and abbreviations are recognized case-insensitively. (This is a change from PostgreSQL versions prior to 8.2, which were case-sensitive in some contexts but not others.)\nNeither timezone names nor abbreviations are hard-wired into the server; they are obtained from configuration files stored under <code>.../share/timezone/</code> and <code>.../share/timezonesets/</code> of the installation directory (see Section B.4).\nThe TimeZone configuration parameter can be set in the file <code>postgresql.conf</code>, or in any of the other standard ways described in Chapter 19. There are also some special ways to set it:\nThe SQL command <code>SET TIME ZONE</code> sets the time zone for the session. This is an alternative spelling of <code>SET TIMEZONE TO</code> with a more SQL-spec-compatible syntax.\nThe <code>PGTZ</code> environment variable is used by libpq clients to send a <code>SET TIME ZONE</code> command to the server upon connection.\n",
            "Internally <code>interval</code> values are stored as months, days, and microseconds. This is done because the number of days in a month varies, and a day can have 23 or 25 hours if a daylight savings time adjustment is involved. The months and days fields are integers while the microseconds field can store fractional seconds. Because intervals are usually created from constant strings or <code>timestamp</code> subtraction, this storage method works well in most cases, but can cause unexpected results:"
        ],
        "Storage Size": "12 bytes",
        "Low Value": "00:00:00+1559",
        "High Value": "24:00:00-1559",
        "Resolution": "1 microsecond",
        "Tree": [
            "(constdatetime TIME ( ) (opt_timezone WITHOUT TIME ZONE))",
            "(constdatetime TIME (opt_timezone WITHOUT TIME ZONE))",
            "(constdatetime TIME ( ))",
            "(constdatetime TIME)"
        ]
    },
    {
        "Type": [
            "time with time zone",
            "timetz",
            "time ( p ) with time zone"
        ],
        "Description": [
            "time with time zone",
            "timetz",
            "time ( 6 ) with time zone"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "<code>time</code>, <code>timestamp</code>, and <code>interval</code> accept an optional precision value <code>p</code> which specifies the number of fractional digits retained in the seconds field. By default, there is no explicit bound on precision. The allowed range of <code>p</code> is from 0 to 6.",
            "The type <code>time with time zone</code> is defined by the SQL standard, but the definition exhibits properties which lead to questionable usefulness. In most cases, a combination of <code>date</code>, <code>time</code>, <code>timestamp without time zone</code>, and <code>timestamp with time zone</code> should provide a complete range of date/time functionality required by any application.",
            "\nDate and time input is accepted in almost any reasonable format, including ISO 8601, SQL-compatible, traditional POSTGRES, and others. For some formats, ordering of day, month, and year in date input is ambiguous and there is support for specifying the expected ordering of these fields. Set the DateStyle parameter to <code>MDY</code> to select month-day-year interpretation, <code>DMY</code> to select day-month-year interpretation, or <code>YMD</code> to select year-month-day interpretation.\nPostgreSQL is more flexible in handling date/time input than the SQL standard requires. See Appendix B for the exact parsing rules of date/time input and for the recognized text fields including months, days of the week, and time zones.\nRemember that any date or time literal input needs to be enclosed in single quotes, like text strings. Refer to Section 4.1.2.7 for more information. SQL requires the following syntax\n<code>\n<code>type</code> [ (<code>p</code>) ] '<code>value</code>'\n</code>\nwhere <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).\n8.5.1.1. Dates\nTable 8.10 shows some possible inputs for the <code>date</code> type.\nTable 8.10. Date Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1999-01-08</td>\n<td>ISO 8601; January 8 in any mode (recommended format)</td>\n</tr>\n<tr>\n<td>January 8, 1999</td>\n<td>unambiguous in any <code>datestyle</code> input mode</td>\n</tr>\n<tr>\n<td>1/8/1999</td>\n<td>January 8 in <code>MDY</code> mode; August 1 in <code>DMY</code> mode</td>\n</tr>\n<tr>\n<td>1/18/1999</td>\n<td>January 18 in <code>MDY</code> mode; rejected in other modes</td>\n</tr>\n<tr>\n<td>01/02/03</td>\n<td>January 2, 2003 in <code>MDY</code> mode; February 1, 2003 in <code>DMY</code> mode; February 3, 2001 in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>1999-Jan-08</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>Jan-08-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>08-Jan-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>99-Jan-08</td>\n<td>January 8 in <code>YMD</code> mode, else error</td>\n</tr>\n<tr>\n<td>08-Jan-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>Jan-08-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>19990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>1999.008</td>\n<td>year and day of year</td>\n</tr>\n<tr>\n<td>J2451187</td>\n<td>Julian date</td>\n</tr>\n<tr>\n<td>January 8, 99 BC</td>\n<td>year 99 BC</td>\n</tr>\n</tbody>\n</table>\n8.5.1.2. Times\nThe time-of-day types are <code>time [ (p) ] without time zone</code> and <code>time [ (p) ] with time zone</code>. <code>time</code> alone is equivalent to <code>time without time zone</code>.\nValid input for these types consists of a time of day followed by an optional time zone. (See Table 8.11 and Table 8.12.) If a time zone is specified in the input for <code>time without time zone</code>, it is silently ignored. You can also specify a date but it will be ignored, except when you use a time zone name that involves a daylight-savings rule, such as <code>America/New_York</code>. In this case specifying the date is required in order to determine whether standard or daylight-savings time applies. The appropriate time zone offset is recorded in the <code>time with time zone</code> value and is output as stored; it is not adjusted to the active time zone.\nTable 8.11. Time Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>04:05:06.789</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05:06</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>040506</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05 AM</code></td>\n<td>same as 04:05; AM does not affect value</td>\n</tr>\n<tr>\n<td><code>04:05 PM</code></td>\n<td>same as 16:05; input hour must be <= 12</td>\n</tr>\n<tr>\n<td><code>04:05:06.789-8</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05:06-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506-08</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+0730</code></td>\n<td>ISO 8601, with fractional-hour time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+07:30:00</code></td>\n<td>UTC offset specified to seconds (not allowed in ISO 8601)</td>\n</tr>\n<tr>\n<td><code>04:05:06 PST</code></td>\n<td>time zone specified by abbreviation</td>\n</tr>\n<tr>\n<td><code>2003-04-12 04:05:06 America/New_York</code></td>\n<td>time zone specified by full name</td>\n</tr>\n</tbody>\n</table>\nTable 8.12. Time Zone Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>PST</code></td>\n<td>Abbreviation (for Pacific Standard Time)</td>\n</tr>\n<tr>\n<td><code>America/New_York</code></td>\n<td>Full time zone name</td>\n</tr>\n<tr>\n<td><code>PST8PDT</code></td>\n<td>POSIX-style time zone specification</td>\n</tr>\n<tr>\n<td><code>-8:00:00</code></td>\n<td>UTC offset for PST</td>\n</tr>\n<tr>\n<td><code>-8:00</code></td>\n<td>UTC offset for PST (ISO 8601 extended format)</td>\n</tr>\n<tr>\n<td><code>-800</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>-8</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>zulu</code></td>\n<td>Military abbreviation for UTC</td>\n</tr>\n<tr>\n<td><code>z</code></td>\n<td>Short form of <code>zulu</code> (also in ISO 8601)</td>\n</tr>\n</tbody>\n</table>\nRefer to Section 8.5.3 for more information on how to specify time zones.\n8.5.1.3. Time Stamps\nValid input for the time stamp types consists of the concatenation of a date and a time, followed by an optional time zone, followed by an optional <code>AD</code> or <code>BC</code>. (Alternatively, <code>AD</code>/<code>BC</code> can appear before the time zone, but this is not the preferred ordering.) Thus:\n<code>\n1999-01-08 04:05:06\n</code>\nand:\n<code>\n1999-01-08 04:05:06 -8:00\n</code>\nare valid values, which follow the ISO 8601 standard. In addition, the common format:\n<code>\nJanuary 8 04:05:06 1999 PST\n</code>\nis supported.\nThe SQL standard differentiates <code>timestamp without time zone</code> and <code>timestamp with time zone</code> literals by the presence of a \"+\" or \"-\" symbol and time zone offset after the time. Hence, according to the standard,\n<code>TIMESTAMP '2004-10-19 10:23:54'</code>\nis a <code>timestamp without time zone</code>, while\n<code>TIMESTAMP '2004-10-19 10:23:54+02'</code>\nis a <code>timestamp with time zone</code>. PostgreSQL never examines the content of a literal string before determining its type, and therefore will treat both of the above as <code>timestamp without time zone</code>. To ensure that a literal is treated as <code>timestamp with time zone</code>, give it the correct explicit type:\n<code>TIMESTAMP WITH TIME ZONE '2004-10-19 10:23:54+02'</code>\nIn a literal that has been determined to be <code>timestamp without time zone</code>, PostgreSQL will silently ignore any time zone indication. That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.\nFor <code>timestamp with time zone</code>, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system's TimeZone parameter, and is converted to UTC using the offset for the <code>timezone</code> zone.\nWhen a <code>timestamp with time zone</code> value is output, it is always converted from UTC to the current <code>timezone</code> zone, and displayed as local time in that zone. To see the time in another time zone, either change <code>timezone</code> or use the <code>AT TIME ZONE</code> construct (see Section 9.9.3).\nConversions between <code>timestamp without time zone</code> and <code>timestamp with time zone</code> normally assume that the <code>timestamp without time zone</code> value should be taken or given as <code>timezone</code> local time. A different time zone can be specified for the conversion using <code>AT TIME ZONE</code>.\n8.5.1.4. Special Values\nPostgreSQL supports several special date/time input values for convenience, as shown in Table 8.13. The values <code>infinity</code> and <code>-infinity</code> are specially represented inside the system and will be displayed unchanged; but the others are simply notational shorthands that will be converted to ordinary date/time values when read. (In particular, <code>now</code> and related strings are converted to a specific time value as soon as they are read.) All of these values need to be enclosed in single quotes when used as constants in SQL commands.\nTable 8.13. Special Date/Time Inputs\n<table>\n<thead>\n<tr>\n<th>Input String</th>\n<th>Valid Types</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>epoch</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>1970-01-01 00:00:00+00 (Unix system time zero)</td>\n</tr>\n<tr>\n<td><code>infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>later than all other time stamps</td>\n</tr>\n<tr>\n<td><code>-infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>earlier than all other time stamps</td>\n</tr>\n<tr>\n<td><code>now</code></td>\n<td><code>date</code>, <code>time</code>, <code>timestamp</code></td>\n<td>current transaction's start time</td>\n</tr>\n<tr>\n<td><code>today</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) today</td>\n</tr>\n<tr>\n<td><code>tomorrow</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) tomorrow</td>\n</tr>\n<tr>\n<td><code>yesterday</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) yesterday</td>\n</tr>\n<tr>\n<td><code>allballs</code></td>\n<td><code>time</code></td>\n<td>00:00:00.00 UTC</td>\n</tr>\n</tbody>\n</table>\nThe following SQL-compatible functions can also be used to obtain the current time value for the corresponding data type: <code>CURRENT_DATE</code>, <code>CURRENT_TIME</code>, <code>CURRENT_TIMESTAMP</code>, <code>LOCALTIME</code>, <code>LOCALTIMESTAMP</code>. (See Section 9.9.4.) Note that these are SQL functions and are not recognized in data input strings.\nCaution\nWhile the input strings <code>now</code>, <code>today</code>, <code>tomorrow</code>, and <code>yesterday</code> are fine to use in interactive SQL commands, they can have surprising behavior when the command is saved to be executed later, for example in prepared statements, views, and function definitions. The string can be converted to a specific time value that continues to be used long after it becomes stale. Use one of the SQL functions instead in such contexts. For example, <code>CURRENT_DATE + 1</code> is safer than <code>'tomorrow'::date</code>.\n",
            "\nThe output format of the date/time types can be set to one of the four styles ISO 8601, SQL (Ingres), traditional POSTGRES (Unix date format), or German. The default is the ISO format. (The SQL standard requires the use of the ISO 8601 format. The name of the \"SQL\" output format is a historical accident.) Table 8.14 shows examples of each output style. The output of the <code>date</code> and <code>time</code> types is generally only the date or time part in accordance with the given examples. However, the POSTGRES style outputs date-only values in ISO format.\nTable 8.14. Date/Time Output Styles\n<table>\n<thead>\n<tr>\n<th>Style Specification</th>\n<th>Description</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ISO</code></td>\n<td>ISO 8601, SQL standard</td>\n<td><code>1997-12-17 07:37:16-08</code></td>\n</tr>\n<tr>\n<td><code>SQL</code></td>\n<td>traditional style</td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres</code></td>\n<td>original style</td>\n<td><code>Wed Dec 17 07:37:16 1997 PST</code></td>\n</tr>\n<tr>\n<td><code>German</code></td>\n<td>regional style</td>\n<td><code>17.12.1997 07:37:16.00 PST</code></td>\n</tr>\n</tbody>\n</table>\nNote\nISO 8601 specifies the use of uppercase letter <code>T</code> to separate the date and time. PostgreSQL accepts that format on input, but on output it uses a space rather than <code>T</code>, as shown above. This is for readability and for consistency with RFC 3339 as well as some other database systems.\nIn the SQL and POSTGRES styles, day appears before month if DMY field ordering has been specified, otherwise month appears before day. (See Section 8.5.1 for how this setting also affects interpretation of input values.) Table 8.15 shows examples.\nTable 8.15. Date Order Conventions\n<table>\n<thead>\n<tr>\n<th><code>datestyle</code> Setting</th>\n<th>Input Ordering</th>\n<th>Example Output</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>SQL, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>17/12/1997 15:37:16.00 CET</code></td>\n</tr>\n<tr>\n<td><code>SQL, MDY</code></td>\n<td><code>month</code>/<code>day</code>/<code>year</code></td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>Wed 17 Dec 07:37:16 1997 PST</code></td>\n</tr>\n</tbody>\n</table>\nIn the ISO style, the time zone is always shown as a signed numeric offset from UTC, with positive sign used for zones east of Greenwich. The offset will be shown as <code>hh</code> (hours only) if it is an integral number of hours, else as <code>hh</code>:<code>mm</code> if it is an integral number of minutes, else as <code>hh</code>:<code>mm</code>:<code>ss</code>. (The third case is not possible with any modern time zone standard, but it can appear when working with timestamps that predate the adoption of standardized time zones.) In the other date styles, the time zone is shown as an alphabetic abbreviation if one is in common use in the current zone. Otherwise it appears as a signed numeric offset in ISO 8601 basic format (<code>hh</code> or <code>hhmm</code>).\nThe date/time style can be selected by the user using the <code>SET datestyle</code> command, the DateStyle parameter in the <code>postgresql.conf</code> configuration file, or the <code>PGDATESTYLE</code> environment variable on the server or client.\nThe formatting function <code>to_char</code> (see Section 9.8) is also available as a more flexible way to format date/time output.\n",
            "\nTime zones, and time-zone conventions, are influenced by political decisions, not just earth geometry. Time zones around the world became somewhat standardized during the 1900s, but continue to be prone to arbitrary changes, particularly with respect to daylight-savings rules. PostgreSQL uses the widely-used IANA (Olson) time zone database for information about historical time zone rules. For times in the future, the assumption is that the latest known rules for a given time zone will continue to be observed indefinitely far into the future.\nPostgreSQL endeavors to be compatible with the SQL standard definitions for typical usage. However, the SQL standard has an odd mix of date and time types and capabilities. Two obvious problems are:\nAlthough the <code>date</code> type cannot have an associated time zone, the <code>time</code> type can. Time zones in the real world have little meaning unless associated with a date as well as a time, since the offset can vary through the year with daylight-saving time boundaries.\nThe default time zone is specified as a constant numeric offset from UTC. It is therefore impossible to adapt to daylight-saving time when doing date/time arithmetic across DST boundaries.\nTo address these difficulties, we recommend using date/time types that contain both date and time when using time zones. We do not recommend using the type <code>time with time zone</code> (though it is supported by PostgreSQL for legacy applications and for compliance with the SQL standard). PostgreSQL assumes your local time zone for any type containing only date or time.\nAll timezone-aware dates and times are stored internally in UTC. They are converted to local time in the zone specified by the TimeZone configuration parameter before being displayed to the client.\nPostgreSQL allows you to specify time zones in three different forms:\nA full time zone name, for example <code>America/New_York</code>. The recognized time zone names are listed in the <code>pg_timezone_names</code> view (see Section 51.92). PostgreSQL uses the widely-used IANA time zone data for this purpose, so the same time zone names are also recognized by other software.\nA time zone abbreviation, for example <code>PST</code>. Such a specification merely defines a particular offset from UTC, in contrast to full time zone names which can imply a set of daylight savings transition rules as well. The recognized abbreviations are listed in the <code>pg_timezone_abbrevs</code> view (see Section 51.91). You cannot set the configuration parameters TimeZone or log_timezone to a time zone abbreviation, but you can use abbreviations in date/time input values and with the <code>AT TIME ZONE</code> operator.\nIn addition to the timezone names and abbreviations, PostgreSQL will accept POSIX-style time zone specifications, as described in Section B.5. This option is not normally preferable to using a named time zone, but it may be necessary if no suitable IANA time zone entry is available.\nIn short, this is the difference between abbreviations and full names: abbreviations represent a specific offset from UTC, whereas many of the full names imply a local daylight-savings time rule, and so have two possible UTC offsets. As an example, <code>2014-06-04 12:00 America/New_York</code> represents noon local time in New York, which for this particular date was Eastern Daylight Time (UTC-4). So <code>2014-06-04 12:00 EDT</code> specifies that same time instant. But <code>2014-06-04 12:00 EST</code> specifies noon Eastern Standard Time (UTC-5), regardless of whether daylight savings was nominally in effect on that date.\nTo complicate matters, some jurisdictions have used the same timezone abbreviation to mean different UTC offsets at different times; for example, in Moscow <code>MSK</code> has meant UTC+3 in some years and UTC+4 in others. PostgreSQL interprets such abbreviations according to whatever they meant (or had most recently meant) on the specified date; but, as with the <code>EST</code> example above, this is not necessarily the same as local civil time on that date.\nIn all cases, timezone names and abbreviations are recognized case-insensitively. (This is a change from PostgreSQL versions prior to 8.2, which were case-sensitive in some contexts but not others.)\nNeither timezone names nor abbreviations are hard-wired into the server; they are obtained from configuration files stored under <code>.../share/timezone/</code> and <code>.../share/timezonesets/</code> of the installation directory (see Section B.4).\nThe TimeZone configuration parameter can be set in the file <code>postgresql.conf</code>, or in any of the other standard ways described in Chapter 19. There are also some special ways to set it:\nThe SQL command <code>SET TIME ZONE</code> sets the time zone for the session. This is an alternative spelling of <code>SET TIMEZONE TO</code> with a more SQL-spec-compatible syntax.\nThe <code>PGTZ</code> environment variable is used by libpq clients to send a <code>SET TIME ZONE</code> command to the server upon connection.\n",
            "Internally <code>interval</code> values are stored as months, days, and microseconds. This is done because the number of days in a month varies, and a day can have 23 or 25 hours if a daylight savings time adjustment is involved. The months and days fields are integers while the microseconds field can store fractional seconds. Because intervals are usually created from constant strings or <code>timestamp</code> subtraction, this storage method works well in most cases, but can cause unexpected results:"
        ],
        "Storage Size": "12 bytes",
        "Low Value": "00:00:00+1559",
        "High Value": "24:00:00-1559",
        "Resolution": "1 microsecond",
        "Tree": [
            "(constdatetime TIME (opt_timezone WITH TIME ZONE))",
            "(identifier TIMETZ)",
            "(constdatetime TIME ( ) (opt_timezone WITH TIME ZONE))"
        ]
    },
    {
        "Type": [
            "date"
        ],
        "Description": [
            "calendar date (year, month, day)",
            "date (no time of day)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "The type <code>time with time zone</code> is defined by the SQL standard, but the definition exhibits properties which lead to questionable usefulness. In most cases, a combination of <code>date</code>, <code>time</code>, <code>timestamp without time zone</code>, and <code>timestamp with time zone</code> should provide a complete range of date/time functionality required by any application.",
            "\nDate and time input is accepted in almost any reasonable format, including ISO 8601, SQL-compatible, traditional POSTGRES, and others. For some formats, ordering of day, month, and year in date input is ambiguous and there is support for specifying the expected ordering of these fields. Set the DateStyle parameter to <code>MDY</code> to select month-day-year interpretation, <code>DMY</code> to select day-month-year interpretation, or <code>YMD</code> to select year-month-day interpretation.\nPostgreSQL is more flexible in handling date/time input than the SQL standard requires. See Appendix B for the exact parsing rules of date/time input and for the recognized text fields including months, days of the week, and time zones.\nRemember that any date or time literal input needs to be enclosed in single quotes, like text strings. Refer to Section 4.1.2.7 for more information. SQL requires the following syntax\n<code>\n<code>type</code> [ (<code>p</code>) ] '<code>value</code>'\n</code>\nwhere <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).\n8.5.1.1. Dates\nTable 8.10 shows some possible inputs for the <code>date</code> type.\nTable 8.10. Date Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1999-01-08</td>\n<td>ISO 8601; January 8 in any mode (recommended format)</td>\n</tr>\n<tr>\n<td>January 8, 1999</td>\n<td>unambiguous in any <code>datestyle</code> input mode</td>\n</tr>\n<tr>\n<td>1/8/1999</td>\n<td>January 8 in <code>MDY</code> mode; August 1 in <code>DMY</code> mode</td>\n</tr>\n<tr>\n<td>1/18/1999</td>\n<td>January 18 in <code>MDY</code> mode; rejected in other modes</td>\n</tr>\n<tr>\n<td>01/02/03</td>\n<td>January 2, 2003 in <code>MDY</code> mode; February 1, 2003 in <code>DMY</code> mode; February 3, 2001 in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>1999-Jan-08</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>Jan-08-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>08-Jan-1999</td>\n<td>January 8 in any mode</td>\n</tr>\n<tr>\n<td>99-Jan-08</td>\n<td>January 8 in <code>YMD</code> mode, else error</td>\n</tr>\n<tr>\n<td>08-Jan-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>Jan-08-99</td>\n<td>January 8, except error in <code>YMD</code> mode</td>\n</tr>\n<tr>\n<td>19990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>990108</td>\n<td>ISO 8601; January 8, 1999 in any mode</td>\n</tr>\n<tr>\n<td>1999.008</td>\n<td>year and day of year</td>\n</tr>\n<tr>\n<td>J2451187</td>\n<td>Julian date</td>\n</tr>\n<tr>\n<td>January 8, 99 BC</td>\n<td>year 99 BC</td>\n</tr>\n</tbody>\n</table>\n8.5.1.2. Times\nThe time-of-day types are <code>time [ (p) ] without time zone</code> and <code>time [ (p) ] with time zone</code>. <code>time</code> alone is equivalent to <code>time without time zone</code>.\nValid input for these types consists of a time of day followed by an optional time zone. (See Table 8.11 and Table 8.12.) If a time zone is specified in the input for <code>time without time zone</code>, it is silently ignored. You can also specify a date but it will be ignored, except when you use a time zone name that involves a daylight-savings rule, such as <code>America/New_York</code>. In this case specifying the date is required in order to determine whether standard or daylight-savings time applies. The appropriate time zone offset is recorded in the <code>time with time zone</code> value and is output as stored; it is not adjusted to the active time zone.\nTable 8.11. Time Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>04:05:06.789</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05:06</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>040506</code></td>\n<td>ISO 8601</td>\n</tr>\n<tr>\n<td><code>04:05 AM</code></td>\n<td>same as 04:05; AM does not affect value</td>\n</tr>\n<tr>\n<td><code>04:05 PM</code></td>\n<td>same as 16:05; input hour must be <= 12</td>\n</tr>\n<tr>\n<td><code>04:05:06.789-8</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05:06-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>04:05-08:00</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506-08</code></td>\n<td>ISO 8601, with time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+0730</code></td>\n<td>ISO 8601, with fractional-hour time zone as UTC offset</td>\n</tr>\n<tr>\n<td><code>040506+07:30:00</code></td>\n<td>UTC offset specified to seconds (not allowed in ISO 8601)</td>\n</tr>\n<tr>\n<td><code>04:05:06 PST</code></td>\n<td>time zone specified by abbreviation</td>\n</tr>\n<tr>\n<td><code>2003-04-12 04:05:06 America/New_York</code></td>\n<td>time zone specified by full name</td>\n</tr>\n</tbody>\n</table>\nTable 8.12. Time Zone Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>PST</code></td>\n<td>Abbreviation (for Pacific Standard Time)</td>\n</tr>\n<tr>\n<td><code>America/New_York</code></td>\n<td>Full time zone name</td>\n</tr>\n<tr>\n<td><code>PST8PDT</code></td>\n<td>POSIX-style time zone specification</td>\n</tr>\n<tr>\n<td><code>-8:00:00</code></td>\n<td>UTC offset for PST</td>\n</tr>\n<tr>\n<td><code>-8:00</code></td>\n<td>UTC offset for PST (ISO 8601 extended format)</td>\n</tr>\n<tr>\n<td><code>-800</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>-8</code></td>\n<td>UTC offset for PST (ISO 8601 basic format)</td>\n</tr>\n<tr>\n<td><code>zulu</code></td>\n<td>Military abbreviation for UTC</td>\n</tr>\n<tr>\n<td><code>z</code></td>\n<td>Short form of <code>zulu</code> (also in ISO 8601)</td>\n</tr>\n</tbody>\n</table>\nRefer to Section 8.5.3 for more information on how to specify time zones.\n8.5.1.3. Time Stamps\nValid input for the time stamp types consists of the concatenation of a date and a time, followed by an optional time zone, followed by an optional <code>AD</code> or <code>BC</code>. (Alternatively, <code>AD</code>/<code>BC</code> can appear before the time zone, but this is not the preferred ordering.) Thus:\n<code>\n1999-01-08 04:05:06\n</code>\nand:\n<code>\n1999-01-08 04:05:06 -8:00\n</code>\nare valid values, which follow the ISO 8601 standard. In addition, the common format:\n<code>\nJanuary 8 04:05:06 1999 PST\n</code>\nis supported.\nThe SQL standard differentiates <code>timestamp without time zone</code> and <code>timestamp with time zone</code> literals by the presence of a \"+\" or \"-\" symbol and time zone offset after the time. Hence, according to the standard,\n<code>TIMESTAMP '2004-10-19 10:23:54'</code>\nis a <code>timestamp without time zone</code>, while\n<code>TIMESTAMP '2004-10-19 10:23:54+02'</code>\nis a <code>timestamp with time zone</code>. PostgreSQL never examines the content of a literal string before determining its type, and therefore will treat both of the above as <code>timestamp without time zone</code>. To ensure that a literal is treated as <code>timestamp with time zone</code>, give it the correct explicit type:\n<code>TIMESTAMP WITH TIME ZONE '2004-10-19 10:23:54+02'</code>\nIn a literal that has been determined to be <code>timestamp without time zone</code>, PostgreSQL will silently ignore any time zone indication. That is, the resulting value is derived from the date/time fields in the input value, and is not adjusted for time zone.\nFor <code>timestamp with time zone</code>, the internally stored value is always in UTC (Universal Coordinated Time, traditionally known as Greenwich Mean Time, GMT). An input value that has an explicit time zone specified is converted to UTC using the appropriate offset for that time zone. If no time zone is stated in the input string, then it is assumed to be in the time zone indicated by the system's TimeZone parameter, and is converted to UTC using the offset for the <code>timezone</code> zone.\nWhen a <code>timestamp with time zone</code> value is output, it is always converted from UTC to the current <code>timezone</code> zone, and displayed as local time in that zone. To see the time in another time zone, either change <code>timezone</code> or use the <code>AT TIME ZONE</code> construct (see Section 9.9.3).\nConversions between <code>timestamp without time zone</code> and <code>timestamp with time zone</code> normally assume that the <code>timestamp without time zone</code> value should be taken or given as <code>timezone</code> local time. A different time zone can be specified for the conversion using <code>AT TIME ZONE</code>.\n8.5.1.4. Special Values\nPostgreSQL supports several special date/time input values for convenience, as shown in Table 8.13. The values <code>infinity</code> and <code>-infinity</code> are specially represented inside the system and will be displayed unchanged; but the others are simply notational shorthands that will be converted to ordinary date/time values when read. (In particular, <code>now</code> and related strings are converted to a specific time value as soon as they are read.) All of these values need to be enclosed in single quotes when used as constants in SQL commands.\nTable 8.13. Special Date/Time Inputs\n<table>\n<thead>\n<tr>\n<th>Input String</th>\n<th>Valid Types</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>epoch</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>1970-01-01 00:00:00+00 (Unix system time zero)</td>\n</tr>\n<tr>\n<td><code>infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>later than all other time stamps</td>\n</tr>\n<tr>\n<td><code>-infinity</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>earlier than all other time stamps</td>\n</tr>\n<tr>\n<td><code>now</code></td>\n<td><code>date</code>, <code>time</code>, <code>timestamp</code></td>\n<td>current transaction's start time</td>\n</tr>\n<tr>\n<td><code>today</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) today</td>\n</tr>\n<tr>\n<td><code>tomorrow</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) tomorrow</td>\n</tr>\n<tr>\n<td><code>yesterday</code></td>\n<td><code>date</code>, <code>timestamp</code></td>\n<td>midnight (<code>00:00</code>) yesterday</td>\n</tr>\n<tr>\n<td><code>allballs</code></td>\n<td><code>time</code></td>\n<td>00:00:00.00 UTC</td>\n</tr>\n</tbody>\n</table>\nThe following SQL-compatible functions can also be used to obtain the current time value for the corresponding data type: <code>CURRENT_DATE</code>, <code>CURRENT_TIME</code>, <code>CURRENT_TIMESTAMP</code>, <code>LOCALTIME</code>, <code>LOCALTIMESTAMP</code>. (See Section 9.9.4.) Note that these are SQL functions and are not recognized in data input strings.\nCaution\nWhile the input strings <code>now</code>, <code>today</code>, <code>tomorrow</code>, and <code>yesterday</code> are fine to use in interactive SQL commands, they can have surprising behavior when the command is saved to be executed later, for example in prepared statements, views, and function definitions. The string can be converted to a specific time value that continues to be used long after it becomes stale. Use one of the SQL functions instead in such contexts. For example, <code>CURRENT_DATE + 1</code> is safer than <code>'tomorrow'::date</code>.\n",
            "\nThe output format of the date/time types can be set to one of the four styles ISO 8601, SQL (Ingres), traditional POSTGRES (Unix date format), or German. The default is the ISO format. (The SQL standard requires the use of the ISO 8601 format. The name of the \"SQL\" output format is a historical accident.) Table 8.14 shows examples of each output style. The output of the <code>date</code> and <code>time</code> types is generally only the date or time part in accordance with the given examples. However, the POSTGRES style outputs date-only values in ISO format.\nTable 8.14. Date/Time Output Styles\n<table>\n<thead>\n<tr>\n<th>Style Specification</th>\n<th>Description</th>\n<th>Example</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>ISO</code></td>\n<td>ISO 8601, SQL standard</td>\n<td><code>1997-12-17 07:37:16-08</code></td>\n</tr>\n<tr>\n<td><code>SQL</code></td>\n<td>traditional style</td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres</code></td>\n<td>original style</td>\n<td><code>Wed Dec 17 07:37:16 1997 PST</code></td>\n</tr>\n<tr>\n<td><code>German</code></td>\n<td>regional style</td>\n<td><code>17.12.1997 07:37:16.00 PST</code></td>\n</tr>\n</tbody>\n</table>\nNote\nISO 8601 specifies the use of uppercase letter <code>T</code> to separate the date and time. PostgreSQL accepts that format on input, but on output it uses a space rather than <code>T</code>, as shown above. This is for readability and for consistency with RFC 3339 as well as some other database systems.\nIn the SQL and POSTGRES styles, day appears before month if DMY field ordering has been specified, otherwise month appears before day. (See Section 8.5.1 for how this setting also affects interpretation of input values.) Table 8.15 shows examples.\nTable 8.15. Date Order Conventions\n<table>\n<thead>\n<tr>\n<th><code>datestyle</code> Setting</th>\n<th>Input Ordering</th>\n<th>Example Output</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>SQL, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>17/12/1997 15:37:16.00 CET</code></td>\n</tr>\n<tr>\n<td><code>SQL, MDY</code></td>\n<td><code>month</code>/<code>day</code>/<code>year</code></td>\n<td><code>12/17/1997 07:37:16.00 PST</code></td>\n</tr>\n<tr>\n<td><code>Postgres, DMY</code></td>\n<td><code>day</code>/<code>month</code>/<code>year</code></td>\n<td><code>Wed 17 Dec 07:37:16 1997 PST</code></td>\n</tr>\n</tbody>\n</table>\nIn the ISO style, the time zone is always shown as a signed numeric offset from UTC, with positive sign used for zones east of Greenwich. The offset will be shown as <code>hh</code> (hours only) if it is an integral number of hours, else as <code>hh</code>:<code>mm</code> if it is an integral number of minutes, else as <code>hh</code>:<code>mm</code>:<code>ss</code>. (The third case is not possible with any modern time zone standard, but it can appear when working with timestamps that predate the adoption of standardized time zones.) In the other date styles, the time zone is shown as an alphabetic abbreviation if one is in common use in the current zone. Otherwise it appears as a signed numeric offset in ISO 8601 basic format (<code>hh</code> or <code>hhmm</code>).\nThe date/time style can be selected by the user using the <code>SET datestyle</code> command, the DateStyle parameter in the <code>postgresql.conf</code> configuration file, or the <code>PGDATESTYLE</code> environment variable on the server or client.\nThe formatting function <code>to_char</code> (see Section 9.8) is also available as a more flexible way to format date/time output.\n",
            "Although the <code>date</code> type cannot have an associated time zone, the <code>time</code> type can. Time zones in the real world have little meaning unless associated with a date as well as a time, since the offset can vary through the year with daylight-saving time boundaries.",
            "<code>\nSELECT EXTRACT(hours from '80 minutes'::interval);\n date_part\n-----------\n 1\nSELECT EXTRACT(days from '80 hours'::interval);\n date_part\n-----------\n 0\n</code>",
            "The output of the <code>postgres_verbose</code> style matches the output of PostgreSQL releases prior to 8.4 when the <code>DateStyle</code> parameter was set to non-<code>ISO</code> output."
        ],
        "Storage Size": "4 bytes",
        "Low Value": "4713 BC",
        "High Value": "5874897 AD",
        "Resolution": "1 day",
        "Tree": [
            "(identifier DATE)"
        ]
    },
    {
        "Type": [
            "interval YEAR",
            "interval MONTH",
            "interval DAY",
            "interval HOUR",
            "interval MINUTE",
            "interval SECOND",
            "interval SECOND ( p )",
            "interval YEAR TO MONTH",
            "interval DAY TO HOUR",
            "interval DAY TO MINUTE",
            "interval DAY TO SECOND",
            "interval DAY TO SECOND ( p )",
            "interval HOUR TO MINUTE",
            "interval HOUR TO MINUTE",
            "interval HOUR TO SECOND",
            "interval HOUR TO SECOND ( p )",
            "interval MINUTE TO SECOND",
            "interval MINUTE TO SECOND ( p )"
        ],
        "Description": [
            "time span",
            "time interval"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-datetime.html",
        "Compensate": [
            "<code>time</code>, <code>timestamp</code>, and <code>interval</code> accept an optional precision value <code>p</code> which specifies the number of fractional digits retained in the seconds field. By default, there is no explicit bound on precision. The allowed range of <code>p</code> is from 0 to 6.",
            "The <code>interval</code> type has an additional option, which is to restrict the set of stored fields by writing one of these phrases:",
            "where <code>p</code> is an optional precision specification giving the number of fractional digits in the seconds field. Precision can be specified for <code>time</code>, <code>timestamp</code>, and <code>interval</code> types, and can range from 0 to 6. If no precision is specified in a constant specification, it defaults to the precision of the literal value (but not more than 6 digits).",
            "\n<code>interval</code> values can be written using the following verbose syntax:\n<code>\n[@] <code>quantity</code> <code>unit</code> [<code>quantity</code> <code>unit</code>...] [<code>direction</code>]\n</code>\nwhere <code>quantity</code> is a number (possibly signed); <code>unit</code> is <code>microsecond</code>, <code>millisecond</code>, <code>second</code>, <code>minute</code>, <code>hour</code>, <code>day</code>, <code>week</code>, <code>month</code>, <code>year</code>, <code>decade</code>, <code>century</code>, <code>millennium</code>, or abbreviations or plurals of these units; <code>direction</code> can be <code>ago</code> or empty. The at sign (<code>@</code>) is optional noise. The amounts of the different units are implicitly added with appropriate sign accounting. <code>ago</code> negates all the fields. This syntax is also used for interval output, if IntervalStyle is set to <code>postgres_verbose</code>.\nQuantities of days, hours, minutes, and seconds can be specified without explicit unit markings. For example, <code>'1 12:59:10'</code> is read the same as <code>'1 day 12 hours 59 min 10 sec'</code>. Also, a combination of years and months can be specified with a dash; for example <code>'200-10'</code> is read the same as <code>'200 years 10 months'</code>. (These shorter forms are in fact the only ones allowed by the SQL standard, and are used for output when <code>IntervalStyle</code> is set to <code>sql_standard</code>.)\nInterval values can also be written as ISO 8601 time intervals, using either the \"format with designators\" of the standard's section 4.4.3.2 or the \"alternative format\" of section 4.4.3.3. The format with designators looks like this:\n<code>\nP <code>quantity</code> <code>unit</code> [ <code>quantity</code> <code>unit</code> ...] [ T [ <code>quantity</code> <code>unit</code> ...]]\n</code>\nThe string must start with a <code>P</code>, and may include a <code>T</code> that introduces the time-of-day units. The available unit abbreviations are given in Table 8.16. Units may be omitted, and may be specified in any order, but units smaller than a day must appear after <code>T</code>. In particular, the meaning of <code>M</code> depends on whether it is before or after <code>T</code>.\nTable 8.16. ISO 8601 Interval Unit Abbreviations\n<table>\n<thead>\n<tr>\n<th>Abbreviation</th>\n<th>Meaning</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Y</td>\n<td>Years</td>\n</tr>\n<tr>\n<td>M</td>\n<td>Months (in the date part)</td>\n</tr>\n<tr>\n<td>W</td>\n<td>Weeks</td>\n</tr>\n<tr>\n<td>D</td>\n<td>Days</td>\n</tr>\n<tr>\n<td>H</td>\n<td>Hours</td>\n</tr>\n<tr>\n<td>M</td>\n<td>Minutes (in the time part)</td>\n</tr>\n<tr>\n<td>S</td>\n<td>Seconds</td>\n</tr>\n</tbody>\n</table>\nIn the alternative format:\n<code>\nP [ <code>years</code>-<code>months</code>-<code>days</code> ] [ T <code>hours</code>:<code>minutes</code>:<code>seconds</code> ]\n</code>\nthe string must begin with <code>P</code>, and a <code>T</code> separates the date and time parts of the interval. The values are given as numbers similar to ISO 8601 dates.\nWhen writing an interval constant with a <code>fields</code> specification, or when assigning a string to an interval column that was defined with a <code>fields</code> specification, the interpretation of unmarked quantities depends on the <code>fields</code>. For example <code>INTERVAL '1' YEAR</code> is read as 1 year, whereas <code>INTERVAL '1'</code> means 1 second. Also, field values \"to the right\" of the least significant field allowed by the <code>fields</code> specification are silently discarded. For example, writing <code>INTERVAL '1 day 2:03:04' HOUR TO MINUTE</code> results in dropping the seconds field, but not the day field.\nAccording to the SQL standard all fields of an interval value must have the same sign, so a leading negative sign applies to all fields; for example the negative sign in the interval literal <code>'-1 2:03:04'</code> applies to both the days and hour/minute/second parts. PostgreSQL allows the fields to have different signs, and traditionally treats each field in the textual representation as independently signed, so that the hour/minute/second part is considered positive in this example. If <code>IntervalStyle</code> is set to <code>sql_standard</code> then a leading sign is considered to apply to all fields (but only if no additional signs appear). Otherwise the traditional PostgreSQL interpretation is used. To avoid ambiguity, it's recommended to attach an explicit sign to each field if any field is negative.\nField values can have fractional parts: for example, <code>'1.5 weeks'</code> or <code>'01:02:03.45'</code>. However, because interval internally stores only three integer units (months, days, microseconds), fractional units must be spilled to smaller units. Fractional parts of units greater than months are truncated to be an integer number of months, e.g. <code>'1.5 years'</code> becomes <code>'1 year 6 mons'</code>. Fractional parts of weeks and days are computed to be an integer number of days and microseconds, assuming 30 days per month and 24 hours per day, e.g., <code>'1.75 months'</code> becomes <code>1 mon 22 days 12:00:00</code>. Only seconds will ever be shown as fractional on output.\nTable 8.17 shows some examples of valid <code>interval</code> input.\nTable 8.17. Interval Input\n<table>\n<thead>\n<tr>\n<th>Example</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1-2</td>\n<td>SQL standard format: 1 year 2 months</td>\n</tr>\n<tr>\n<td>3 4:05:06</td>\n<td>SQL standard format: 3 days 4 hours 5 minutes 6 seconds</td>\n</tr>\n<tr>\n<td>1 year 2 months 3 days 4 hours 5 minutes 6 seconds</td>\n<td>Traditional Postgres format: 1 year 2 months 3 days 4 hours 5 minutes 6 seconds</td>\n</tr>\n<tr>\n<td>P1Y2M3DT4H5M6S</td>\n<td>ISO 8601 \"format with designators\": same meaning as above</td>\n</tr>\n<tr>\n<td>P0001-02-03T04:05:06</td>\n<td>ISO 8601 \"alternative format\": same meaning as above</td>\n</tr>\n</tbody>\n</table>\nInternally <code>interval</code> values are stored as months, days, and microseconds. This is done because the number of days in a month varies, and a day can have 23 or 25 hours if a daylight savings time adjustment is involved. The months and days fields are integers while the microseconds field can store fractional seconds. Because intervals are usually created from constant strings or <code>timestamp</code> subtraction, this storage method works well in most cases, but can cause unexpected results:\n<code>\nSELECT EXTRACT(hours from '80 minutes'::interval);\n date_part\n-----------\n 1\nSELECT EXTRACT(days from '80 hours'::interval);\n date_part\n-----------\n 0\n</code>\nFunctions <code>justify_days</code> and <code>justify_hours</code> are available for adjusting days and hours that overflow their normal ranges.\n",
            "\nThe output format of the interval type can be set to one of the four styles <code>sql_standard</code>, <code>postgres</code>, <code>postgres_verbose</code>, or <code>iso_8601</code>, using the command <code>SET intervalstyle</code>. The default is the <code>postgres</code> format. Table 8.18 shows examples of each output style.\nThe <code>sql_standard</code> style produces output that conforms to the SQL standard's specification for interval literal strings, if the interval value meets the standard's restrictions (either year-month only or day-time only, with no mixing of positive and negative components). Otherwise the output looks like a standard year-month literal string followed by a day-time literal string, with explicit signs added to disambiguate mixed-sign intervals.\nThe output of the <code>postgres</code> style matches the output of PostgreSQL releases prior to 8.4 when the DateStyle parameter was set to <code>ISO</code>.\nThe output of the <code>postgres_verbose</code> style matches the output of PostgreSQL releases prior to 8.4 when the <code>DateStyle</code> parameter was set to non-<code>ISO</code> output.\nThe output of the <code>iso_8601</code> style matches the \"format with designators\" described in section 4.4.3.2 of the ISO 8601 standard.\nTable 8.18. Interval Output Style Examples\n<table>\n<thead>\n<tr>\n<th>Style Specification</th>\n<th>Year-Month Interval</th>\n<th>Day-Time Interval</th>\n<th>Mixed Interval</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>sql_standard</code></td>\n<td>1-2</td>\n<td>3 4:05:06</td>\n<td>-1-2 +3 -4:05:06</td>\n</tr>\n<tr>\n<td><code>postgres</code></td>\n<td>1 year 2 mons</td>\n<td>3 days 04:05:06</td>\n<td>-1 year -2 mons +3 days -04:05:06</td>\n</tr>\n<tr>\n<td><code>postgres_verbose</code></td>\n<td>@ 1 year 2 mons</td>\n<td>@ 3 days 4 hours 5 mins 6 secs</td>\n<td>@ 1 year 2 mons -3 days 4 hours 5 mins 6 secs ago</td>\n</tr>\n<tr>\n<td><code>iso_8601</code></td>\n<td>P1Y2M</td>\n<td>P3DT4H5M6S</td>\n<td>P-1Y-2M3DT-4H-5M-6S</td>\n</tr>\n</tbody>\n</table>\n"
        ],
        "Storage Size": "16 bytes",
        "Low Value": "-178000000 years",
        "High Value": "178000000 years",
        "Resolution": "1 microsecond",
        "Tree": [
            "(simpletypename (constinterval INTERVAL) (opt_interval YEAR))",
            "(simpletypename (constinterval INTERVAL) (opt_interval MONTH))",
            "(simpletypename (constinterval INTERVAL) (opt_interval DAY))",
            "(simpletypename (constinterval INTERVAL) (opt_interval HOUR))",
            "(simpletypename (constinterval INTERVAL) (opt_interval MINUTE))",
            "(simpletypename (constinterval INTERVAL) (opt_interval (interval_second SECOND)))",
            "(simpletypename (constinterval INTERVAL) (opt_interval (interval_second SECOND ( ))))",
            "(simpletypename (constinterval INTERVAL) (opt_interval YEAR TO MONTH))",
            "(simpletypename (constinterval INTERVAL) (opt_interval DAY TO HOUR))",
            "(simpletypename (constinterval INTERVAL) (opt_interval DAY TO MINUTE))",
            "(simpletypename (constinterval INTERVAL) (opt_interval DAY TO (interval_second SECOND)))",
            "(simpletypename (constinterval INTERVAL) (opt_interval DAY TO (interval_second SECOND ( ))))",
            "(simpletypename (constinterval INTERVAL) (opt_interval HOUR TO MINUTE))",
            "(simpletypename (constinterval INTERVAL) (opt_interval HOUR TO MINUTE))",
            "(simpletypename (constinterval INTERVAL) (opt_interval HOUR TO (interval_second SECOND)))",
            "(simpletypename (constinterval INTERVAL) (opt_interval HOUR TO (interval_second SECOND ( ))))",
            "(simpletypename (constinterval INTERVAL) (opt_interval MINUTE TO (interval_second SECOND)))",
            "(simpletypename (constinterval INTERVAL) (opt_interval MINUTE TO (interval_second SECOND ( ))))"
        ]
    },
    {
        "Type": [
            "boolean",
            "bool"
        ],
        "Description": [
            "logical Boolean (true/false)",
            "state of true or false"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-boolean.html",
        "Compensate": [
            "PostgreSQL provides the standard SQL type <code>boolean</code>; see Table 8.19. The <code>boolean</code> type can have several states: \"true\", \"false\", and a third state, \"unknown\", which is represented by the SQL null value.",
            "The datatype input function for type <code>boolean</code> accepts these string representations for the \"true\" state:",
            "The datatype output function for type <code>boolean</code> always emits either <code>t</code> or <code>f</code>, as shown in Example 8.2.",
            "Example 8.2. Using the <code>boolean</code> Type",
            "<code>\nCREATE TABLE test1 (a boolean, b text);\nINSERT INTO test1 VALUES (TRUE, 'sic est');\nINSERT INTO test1 VALUES (FALSE, 'non est');\nSELECT * FROM test1;\n a | b\n---+---------\n t | sic est\n f | non est\nSELECT * FROM test1 WHERE a;\n a | b\n---+---------\n t | sic est\n</code>",
            "The key words <code>TRUE</code> and <code>FALSE</code> are the preferred (SQL-compliant) method for writing Boolean constants in SQL queries. But you can also use the string representations by following the generic string-literal constant syntax described in Section 4.1.2.7, for example <code>'yes'::boolean</code>.",
            "Note that the parser automatically understands that <code>TRUE</code> and <code>FALSE</code> are of type <code>boolean</code>, but this is not so for <code>NULL</code> because that can have any type. So in some contexts you might have to cast <code>NULL</code> to <code>boolean</code> explicitly, for example <code>NULL::boolean</code>. Conversely, the cast can be omitted from a string-literal Boolean value in contexts where the parser can deduce that the literal must be of type <code>boolean</code>."
        ],
        "Storage Size": "1 byte",
        "Tree": [
            "(numeric BOOLEAN)",
            "(identifier BOOL)"
        ]
    },
    {
        "Type": [
            "point"
        ],
        "Description": [
            "geometric point on a plane",
            "Point on a plane"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nPoints are the fundamental two-dimensional building block for geometric types. Values of type <code>point</code> are specified using either of the following syntaxes:\n<code>\n( <code>x</code> , <code>y</code> )\n <code>x</code> , <code>y</code>\n</code>\nwhere <code>x</code> and <code>y</code> are the respective coordinates, as floating-point numbers.\nPoints are output using the first syntax.\n"
        ],
        "Storage Size": "16 bytes",
        "Representation": "(x,y)",
        "Tree": [
            "(identifier POINT)"
        ]
    },
    {
        "Type": [
            "line"
        ],
        "Description": [
            "infinite line on a plane",
            "Infinite line"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nLines are represented by the linear equation <code>A</code>x + <code>B</code>y + <code>C</code> = 0, where <code>A</code> and <code>B</code> are not both zero. Values of type <code>line</code> are input and output in the following form:\n<code>\n{ <code>A</code>, <code>B</code>, <code>C</code> }\n</code>\nAlternatively, any of the following forms can be used for input:\n<code>\n[ ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> ) ]\n( ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> ) )\n ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> )\n <code>x1</code> , <code>y1</code> , <code>x2</code> , <code>y2</code>\n</code>\nwhere <code>(x1,y1)</code> and <code>(x2,y2)</code> are two different points on the line.\n",
            "\nLine segments are represented by pairs of points that are the endpoints of the segment. Values of type <code>lseg</code> are specified using any of the following syntaxes:\n<code>\n[ ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> ) ]\n( ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> ) )\n ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> )\n <code>x1</code> , <code>y1</code> , <code>x2</code> , <code>y2</code>\n</code>\nwhere <code>(x1,y1)</code> and <code>(x2,y2)</code> are the end points of the line segment.\nLine segments are output using the first syntax.\n"
        ],
        "Storage Size": "24 bytes",
        "Representation": "{A,B,C}",
        "Tree": [
            "(identifier LINE)"
        ]
    },
    {
        "Type": [
            "lseg"
        ],
        "Description": [
            "line segment on a plane",
            "Finite line segment"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "Line segments are represented by pairs of points that are the endpoints of the segment. Values of type <code>lseg</code> are specified using any of the following syntaxes:"
        ],
        "Storage Size": "32 bytes",
        "Representation": "((x1,y1),(x2,y2))",
        "Tree": [
            "(identifier LSEG)"
        ]
    },
    {
        "Type": [
            "box"
        ],
        "Description": [
            "rectangular box on a plane",
            "Rectangular box"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nBoxes are represented by pairs of points that are opposite corners of the box. Values of type <code>box</code> are specified using any of the following syntaxes:\n<code>\n( ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> ) )\n ( <code>x1</code> , <code>y1</code> ) , ( <code>x2</code> , <code>y2</code> )\n <code>x1</code> , <code>y1</code> , <code>x2</code> , <code>y2</code>\n</code>\nwhere <code>(x1,y1)</code> and <code>(x2,y2)</code> are any two opposite corners of the box.\nBoxes are output using the second syntax.\nAny two opposite corners can be supplied on input, but the values will be reordered as needed to store the upper right and lower left corners, in that order.\n"
        ],
        "Storage Size": "32 bytes",
        "Representation": "((x1,y1),(x2,y2))",
        "Tree": [
            "(identifier BOX)"
        ]
    },
    {
        "Type": [
            "path"
        ],
        "Description": [
            "geometric path on a plane",
            "Closed path (similar to polygon)",
            "Open path"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nPaths are represented by lists of connected points. Paths can be open, where the first and last points in the list are considered not connected, or closed, where the first and last points are considered connected.\nValues of type <code>path</code> are specified using any of the following syntaxes:\n<code>\n[ ( <code>x1</code> , <code>y1</code> ) , ... , ( <code>xn</code> , <code>yn</code> ) ]\n( ( <code>x1</code> , <code>y1</code> ) , ... , ( <code>xn</code> , <code>yn</code> ) )\n ( <code>x1</code> , <code>y1</code> ) , ... , ( <code>xn</code> , <code>yn</code> )\n ( <code>x1</code> , <code>y1</code> , ... , <code>xn</code> , <code>yn</code> )\n <code>x1</code> , <code>y1</code> , ... , <code>xn</code> , <code>yn</code>\n</code>\nwhere the points are the end points of the line segments comprising the path. Square brackets (<code>[]</code>) indicate an open path, while parentheses (<code>()</code>) indicate a closed path. When the outermost parentheses are omitted, as in the third through fifth syntaxes, a closed path is assumed.\nPaths are output using the first or second syntax, as appropriate.\n"
        ],
        "Storage Size": "16+16n bytes",
        "Representation": "[(x1,y1),...]",
        "Tree": [
            "(identifier PATH)"
        ]
    },
    {
        "Type": [
            "polygon"
        ],
        "Description": [
            "closed geometric path on a plane",
            "Polygon (similar to closed path)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nPolygons are represented by lists of points (the vertexes of the polygon). Polygons are very similar to closed paths; the essential semantic difference is that a polygon is considered to include the area within it, while a path is not.\nAn important implementation difference between polygons and paths is that the stored representation of a polygon includes its smallest bounding box. This speeds up certain search operations, although computing the bounding box adds overhead while constructing new polygons.\nValues of type <code>polygon</code> are specified using any of the following syntaxes:\n<code>\n( ( <code>x1</code> , <code>y1</code> ) , ... , ( <code>xn</code> , <code>yn</code> ) )\n ( <code>x1</code> , <code>y1</code> ) , ... , ( <code>xn</code> , <code>yn</code> )\n ( <code>x1</code> , <code>y1</code> , ... , <code>xn</code> , <code>yn</code> )\n <code>x1</code> , <code>y1</code> , ... , <code>xn</code> , <code>yn</code>\n</code>\nwhere the points are the end points of the line segments comprising the boundary of the polygon.\nPolygons are output using the first syntax.\n"
        ],
        "Storage Size": "40+16n bytes",
        "Representation": "((x1,y1),...)",
        "Tree": [
            "(identifier POLYGON)"
        ]
    },
    {
        "Type": [
            "circle"
        ],
        "Description": [
            "circle on a plane"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-geometric.html",
        "Compensate": [
            "\nCircles are represented by a center point and radius. Values of type <code>circle</code> are specified using any of the following syntaxes:\n<code>\n< ( <code>x</code> , <code>y</code> ) , <code>r</code> >\n( ( <code>x</code> , <code>y</code> ) , <code>r</code> )\n ( <code>x</code> , <code>y</code> ) , <code>r</code>\n <code>x</code> , <code>y</code> , <code>r</code>\n</code>\nwhere <code>(x,y)</code> is the center point and <code>r</code> is the radius of the circle.\nCircles are output using the first syntax.\n"
        ],
        "Storage Size": "24 bytes",
        "Representation": "<(x,y),r> (center point and radius)",
        "Tree": [
            "(identifier CIRCLE)"
        ]
    },
    {
        "Type": [
            "cidr"
        ],
        "Description": [
            "IPv4 or IPv6 network address"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-net-types.html",
        "Compensate": [
            "When sorting <code>inet</code> or <code>cidr</code> data types, IPv4 addresses will always sort before IPv6 addresses, including IPv4 addresses encapsulated or mapped to IPv6 addresses, such as ::10.2.3.4 or ::ffff:10.4.3.2.",
            "The <code>inet</code> type holds an IPv4 or IPv6 host address, and optionally its subnet, all in one field. The subnet is represented by the number of network address bits present in the host address (the \"netmask\"). If the netmask is 32 and the address is IPv4, then the value does not indicate a subnet, only a single host. In IPv6, the address length is 128 bits, so 128 bits specify a unique host address. Note that if you want to accept only networks, you should use the <code>cidr</code> type rather than <code>inet</code>.",
            "\nThe <code>cidr</code> type holds an IPv4 or IPv6 network specification. Input and output formats follow Classless Internet Domain Routing conventions. The format for specifying networks is <code>address/y</code> where <code>address</code> is the network represented as an IPv4 or IPv6 address, and <code>y</code> is the number of bits in the netmask. If <code>y</code> is omitted, it is calculated using assumptions from the older classful network numbering system, except it will be at least large enough to include all of the octets written in the input. It is an error to specify a network address that has bits set to the right of the specified netmask.\nTable 8.22 shows some examples.\nTable 8.22. <code>cidr</code> Type Input Examples\n<table>\n<thead>\n<tr>\n<th><code>cidr</code> Input</th>\n<th><code>cidr</code> Output</th>\n<th><code>abbrev(cidr)</code></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>192.168.100.128/25</td>\n<td>192.168.100.128/25</td>\n<td>192.168.100.128/25</td>\n</tr>\n<tr>\n<td>192.168/24</td>\n<td>192.168.0.0/24</td>\n<td>192.168.0/24</td>\n</tr>\n<tr>\n<td>192.168/25</td>\n<td>192.168.0.0/25</td>\n<td>192.168.0.0/25</td>\n</tr>\n<tr>\n<td>192.168.1</td>\n<td>192.168.1.0/24</td>\n<td>192.168.1/24</td>\n</tr>\n<tr>\n<td>192.168</td>\n<td>192.168.0.0/24</td>\n<td>192.168.0/24</td>\n</tr>\n<tr>\n<td>128.1</td>\n<td>128.1.0.0/16</td>\n<td>128.1/16</td>\n</tr>\n<tr>\n<td>128</td>\n<td>128.0.0.0/16</td>\n<td>128.0/16</td>\n</tr>\n<tr>\n<td>128.1.2</td>\n<td>128.1.2.0/24</td>\n<td>128.1.2/24</td>\n</tr>\n<tr>\n<td>10.1.2</td>\n<td>10.1.2.0/24</td>\n<td>10.1.2/24</td>\n</tr>\n<tr>\n<td>10.1</td>\n<td>10.1.0.0/16</td>\n<td>10.1/16</td>\n</tr>\n<tr>\n<td>10</td>\n<td>10.0.0.0/8</td>\n<td>10/8</td>\n</tr>\n<tr>\n<td>10.1.2.3/32</td>\n<td>10.1.2.3/32</td>\n<td>10.1.2.3/32</td>\n</tr>\n<tr>\n<td>2001:4f8:3:ba::/64</td>\n<td>2001:4f8:3:ba::/64</td>\n<td>2001:4f8:3:ba::/64</td>\n</tr>\n<tr>\n<td>2001:4f8:3:ba:2e0:81ff:fe22:d1f1/128</td>\n<td>2001:4f8:3:ba:2e0:81ff:fe22:d1f1/128</td>\n<td>2001:4f8:3:ba:2e0:81ff:fe22:d1f1</td>\n</tr>\n<tr>\n<td>::ffff:1.2.3.0/120</td>\n<td>::ffff:1.2.3.0/120</td>\n<td>::ffff:1.2.3/120</td>\n</tr>\n<tr>\n<td>::ffff:1.2.3.0/128</td>\n<td>::ffff:1.2.3.0/128</td>\n<td>::ffff:1.2.3.0/128</td>\n</tr>\n</tbody>\n</table>\n",
            "\nThe essential difference between <code>inet</code> and <code>cidr</code> data types is that <code>inet</code> accepts values with nonzero bits to the right of the netmask, whereas <code>cidr</code> does not. For example, <code>192.168.0.1/24</code> is valid for <code>inet</code> but not for <code>cidr</code>.\nTip\nIf you do not like the output format for <code>inet</code> or <code>cidr</code> values, try the functions <code>host</code>, <code>text</code>, and <code>abbrev</code>.\n"
        ],
        "Storage Size": "7 or 19 bytes",
        "Tree": [
            "(identifier CIDR)"
        ]
    },
    {
        "Type": [
            "inet"
        ],
        "Description": [
            "IPv4 or IPv6 host address",
            "IPv4 and IPv6 hosts and networks"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-net-types.html",
        "Compensate": [
            "When sorting <code>inet</code> or <code>cidr</code> data types, IPv4 addresses will always sort before IPv6 addresses, including IPv4 addresses encapsulated or mapped to IPv6 addresses, such as ::10.2.3.4 or ::ffff:10.4.3.2.",
            "\nThe <code>inet</code> type holds an IPv4 or IPv6 host address, and optionally its subnet, all in one field. The subnet is represented by the number of network address bits present in the host address (the \"netmask\"). If the netmask is 32 and the address is IPv4, then the value does not indicate a subnet, only a single host. In IPv6, the address length is 128 bits, so 128 bits specify a unique host address. Note that if you want to accept only networks, you should use the <code>cidr</code> type rather than <code>inet</code>.\nThe input format for this type is <code>address/y</code> where <code>address</code> is an IPv4 or IPv6 address and <code>y</code> is the number of bits in the netmask. If the <code>/y</code> portion is missing, the netmask is 32 for IPv4 and 128 for IPv6, so the value represents just a single host. On display, the <code>/y</code> portion is suppressed if the netmask specifies a single host.\n",
            "\nThe essential difference between <code>inet</code> and <code>cidr</code> data types is that <code>inet</code> accepts values with nonzero bits to the right of the netmask, whereas <code>cidr</code> does not. For example, <code>192.168.0.1/24</code> is valid for <code>inet</code> but not for <code>cidr</code>.\nTip\nIf you do not like the output format for <code>inet</code> or <code>cidr</code> values, try the functions <code>host</code>, <code>text</code>, and <code>abbrev</code>.\n"
        ],
        "Storage Size": "7 or 19 bytes",
        "Tree": [
            "(identifier INET)"
        ]
    },
    {
        "Type": [
            "macaddr"
        ],
        "Description": [
            "MAC (Media Access Control) address",
            "MAC addresses (EUI-64 format)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-net-types.html",
        "Compensate": [
            "\nThe <code>macaddr</code> type stores MAC addresses, known for example from Ethernet card hardware addresses (although MAC addresses are used for other purposes as well). Input is accepted in the following formats:\n<table>\n<tr>\n<td><code>'08:00:2b:01:02:03'</code></td>\n</tr>\n<tr>\n<td><code>'08-00-2b-01-02-03'</code></td>\n</tr>\n<tr>\n<td><code>'08002b:010203'</code></td>\n</tr>\n<tr>\n<td><code>'08002b-010203'</code></td>\n</tr>\n<tr>\n<td><code>'0800.2b01.0203'</code></td>\n</tr>\n<tr>\n<td><code>'0800-2b01-0203'</code></td>\n</tr>\n<tr>\n<td><code>'08002b010203'</code></td>\n</tr>\n</table>\nThese examples would all specify the same address. Upper and lower case is accepted for the digits <code>a</code> through <code>f</code>. Output is always in the first of the forms shown.\nIEEE Standard 802-2001 specifies the second form shown (with hyphens) as the canonical form for MAC addresses, and specifies the first form (with colons) as used with bit-reversed, MSB-first notation, so that 08-00-2b-01-02-03 = 10:00:D4:80:40:C0. This convention is widely ignored nowadays, and it is relevant only for obsolete network protocols (such as Token Ring). PostgreSQL makes no provisions for bit reversal; all accepted formats use the canonical LSB order.\nThe remaining five input formats are not part of any standard.\n",
            "\nThe <code>macaddr8</code> type stores MAC addresses in EUI-64 format, known for example from Ethernet card hardware addresses (although MAC addresses are used for other purposes as well). This type can accept both 6 and 8 byte length MAC addresses and stores them in 8 byte length format. MAC addresses given in 6 byte format will be stored in 8 byte length format with the 4th and 5th bytes set to FF and FE, respectively. Note that IPv6 uses a modified EUI-64 format where the 7th bit should be set to one after the conversion from EUI-48. The function <code>macaddr8_set7bit</code> is provided to make this change. Generally speaking, any input which is comprised of pairs of hex digits (on byte boundaries), optionally separated consistently by one of <code>':'</code>, <code>'-'</code> or <code>'.'</code>, is accepted. The number of hex digits must be either 16 (8 bytes) or 12 (6 bytes). Leading and trailing whitespace is ignored. The following are examples of input formats that are accepted:\n<table>\n<tr>\n<td><code>'08:00:2b:01:02:03:04:05'</code></td>\n</tr>\n<tr>\n<td><code>'08-00-2b-01-02-03-04-05'</code></td>\n</tr>\n<tr>\n<td><code>'08002b:0102030405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b-0102030405'</code></td>\n</tr>\n<tr>\n<td><code>'0800.2b01.0203.0405'</code></td>\n</tr>\n<tr>\n<td><code>'0800-2b01-0203-0405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b01:02030405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b0102030405'</code></td>\n</tr>\n</table>\nThese examples would all specify the same address. Upper and lower case is accepted for the digits <code>a</code> through <code>f</code>. Output is always in the first of the forms shown. The last six input formats that are mentioned above are not part of any standard. To convert a traditional 48 bit MAC address in EUI-48 format to modified EUI-64 format to be included as the host portion of an IPv6 address, use <code>macaddr8_set7bit</code> as shown:\n<code>\nSELECT macaddr8_set7bit('08:00:2b:01:02:03');\n<code>\n macaddr8_set7bit \n-------------------------\n 0a:00:2b:ff:fe:01:02:03\n(1 row)\n</code>\n</code>\n"
        ],
        "Storage Size": "8 bytes",
        "Tree": [
            "(identifier MACADDR)"
        ]
    },
    {
        "Type": [
            "macaddr8"
        ],
        "Description": [
            "MAC (Media Access Control) address (EUI-64 format)",
            "MAC addresses (EUI-64 format)"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-net-types.html",
        "Compensate": [
            "\nThe <code>macaddr8</code> type stores MAC addresses in EUI-64 format, known for example from Ethernet card hardware addresses (although MAC addresses are used for other purposes as well). This type can accept both 6 and 8 byte length MAC addresses and stores them in 8 byte length format. MAC addresses given in 6 byte format will be stored in 8 byte length format with the 4th and 5th bytes set to FF and FE, respectively. Note that IPv6 uses a modified EUI-64 format where the 7th bit should be set to one after the conversion from EUI-48. The function <code>macaddr8_set7bit</code> is provided to make this change. Generally speaking, any input which is comprised of pairs of hex digits (on byte boundaries), optionally separated consistently by one of <code>':'</code>, <code>'-'</code> or <code>'.'</code>, is accepted. The number of hex digits must be either 16 (8 bytes) or 12 (6 bytes). Leading and trailing whitespace is ignored. The following are examples of input formats that are accepted:\n<table>\n<tr>\n<td><code>'08:00:2b:01:02:03:04:05'</code></td>\n</tr>\n<tr>\n<td><code>'08-00-2b-01-02-03-04-05'</code></td>\n</tr>\n<tr>\n<td><code>'08002b:0102030405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b-0102030405'</code></td>\n</tr>\n<tr>\n<td><code>'0800.2b01.0203.0405'</code></td>\n</tr>\n<tr>\n<td><code>'0800-2b01-0203-0405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b01:02030405'</code></td>\n</tr>\n<tr>\n<td><code>'08002b0102030405'</code></td>\n</tr>\n</table>\nThese examples would all specify the same address. Upper and lower case is accepted for the digits <code>a</code> through <code>f</code>. Output is always in the first of the forms shown. The last six input formats that are mentioned above are not part of any standard. To convert a traditional 48 bit MAC address in EUI-48 format to modified EUI-64 format to be included as the host portion of an IPv6 address, use <code>macaddr8_set7bit</code> as shown:\n<code>\nSELECT macaddr8_set7bit('08:00:2b:01:02:03');\n<code>\n macaddr8_set7bit \n-------------------------\n 0a:00:2b:ff:fe:01:02:03\n(1 row)\n</code>\n</code>\n"
        ],
        "Storage Size": "8 bytes",
        "Tree": [
            "(identifier MACADDR8)"
        ]
    },
    {
        "Type": [
            "bit ( n )",
            "bit"
        ],
        "Description": [
            "fixed-length bit string"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-bit.html",
        "Compensate": [
            "Bit strings are strings of 1's and 0's. They can be used to store or visualize bit masks. There are two SQL bit types: <code>bit(n)</code> and <code>bit varying(n)</code>, where <code>n</code> is a positive integer.",
            "<code>bit</code> type data must match the length <code>n</code> exactly; it is an error to attempt to store shorter or longer bit strings. <code>bit varying</code> data is of variable length up to the maximum length <code>n</code>; longer strings will be rejected. Writing <code>bit</code> without a length is equivalent to <code>bit(1)</code>, while <code>bit varying</code> without a length specification means unlimited length.",
            "If one explicitly casts a bit-string value to <code>bit(n)</code>, it will be truncated or zero-padded on the right to be exactly <code>n</code> bits, without raising an error. Similarly, if one explicitly casts a bit-string value to <code>bit varying(n)</code>, it will be truncated on the right if it is more than <code>n</code> bits.",
            "<code>\nCREATE TABLE test (a BIT(3), b BIT VARYING(5));\nINSERT INTO test VALUES (B'101', B'00');\nINSERT INTO test VALUES (B'10', B'101');\nERROR: bit string length 2 does not match type bit(3)\nINSERT INTO test VALUES (B'10'::bit(3), B'101');\nSELECT * FROM test;\n a | b\n-----+-----\n 101 | 00\n 100 | 101\n</code>"
        ],
        "Tree": [
            "(bitwithlength BIT ( ))",
            "(bitwithoutlength BIT)"
        ]
    },
    {
        "Type": [
            "bit varying ( n )",
            "varbit ( n )",
            "bit varying",
            "varbit"
        ],
        "Description": [
            "variable-length bit string"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-bit.html",
        "Compensate": [
            "Bit strings are strings of 1's and 0's. They can be used to store or visualize bit masks. There are two SQL bit types: <code>bit(n)</code> and <code>bit varying(n)</code>, where <code>n</code> is a positive integer.",
            "<code>bit</code> type data must match the length <code>n</code> exactly; it is an error to attempt to store shorter or longer bit strings. <code>bit varying</code> data is of variable length up to the maximum length <code>n</code>; longer strings will be rejected. Writing <code>bit</code> without a length is equivalent to <code>bit(1)</code>, while <code>bit varying</code> without a length specification means unlimited length.",
            "If one explicitly casts a bit-string value to <code>bit(n)</code>, it will be truncated or zero-padded on the right to be exactly <code>n</code> bits, without raising an error. Similarly, if one explicitly casts a bit-string value to <code>bit varying(n)</code>, it will be truncated on the right if it is more than <code>n</code> bits.",
            "<code>\nCREATE TABLE test (a BIT(3), b BIT VARYING(5));\nINSERT INTO test VALUES (B'101', B'00');\nINSERT INTO test VALUES (B'10', B'101');\nERROR: bit string length 2 does not match type bit(3)\nINSERT INTO test VALUES (B'10'::bit(3), B'101');\nSELECT * FROM test;\n a | b\n-----+-----\n 101 | 00\n 100 | 101\n</code>"
        ],
        "Tree": [
            "(bitwithlength BIT (opt_varying VARYING) ( ))",
            "(generictype (type_function_name (identifier VARBIT)) (opt_type_modifiers ( )))",
            "(bitwithoutlength BIT (opt_varying VARYING))",
            "(identifier VARBIT)"
        ]
    },
    {
        "Type": [
            "tsquery"
        ],
        "Description": [
            "text search query"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-textsearch.html",
        "Compensate": [
            "PostgreSQL provides two data types that are designed to support full text search, which is the activity of searching through a collection of natural-language documents to locate those that best match a query. The <code>tsvector</code> type represents a document in a form optimized for text search; the <code>tsquery</code> type similarly represents a text query. Chapter 12 provides a detailed explanation of this facility, and Section 9.13 summarizes the related functions and operators.",
            "\nA <code>tsquery</code> value stores lexemes that are to be searched for, and can combine them using the Boolean operators <code>&</code> (AND), <code>|</code> (OR), and <code>!</code> (NOT), as well as the phrase search operator <code><-></code> (FOLLOWED BY). There is also a variant <code><N></code> of the FOLLOWED BY operator, where <code>N</code> is an integer constant that specifies the distance between the two lexemes being searched for. <code><-></code> is equivalent to <code><1></code>.\nParentheses can be used to enforce grouping of these operators. In the absence of parentheses, <code>!</code> (NOT) binds most tightly, <code><-></code> (FOLLOWED BY) next most tightly, then <code>&</code> (AND), with <code>|</code> (OR) binding the least tightly.\nHere are some examples:\n<code>\nSELECT 'fat & rat'::tsquery;\n tsquery \n---------------\n 'fat' & 'rat'\nSELECT 'fat & (rat | cat)'::tsquery;\n tsquery \n---------------------------\n 'fat' & ( 'rat' | 'cat' )\nSELECT 'fat & rat & ! cat'::tsquery;\n tsquery \n------------------------\n 'fat' & 'rat' & !'cat'\n</code>\nOptionally, lexemes in a <code>tsquery</code> can be labeled with one or more weight letters, which restricts them to match only <code>tsvector</code> lexemes with one of those weights:\n<code>\nSELECT 'fat:ab & cat'::tsquery;\n tsquery\n------------------\n 'fat':AB & 'cat'\n</code>\nAlso, lexemes in a <code>tsquery</code> can be labeled with <code>*</code> to specify prefix matching:\n<code>\nSELECT 'super:*'::tsquery;\n tsquery \n-----------\n 'super':*\n</code>\nThis query will match any word in a <code>tsvector</code> that begins with \"super\".\nQuoting rules for lexemes are the same as described previously for lexemes in <code>tsvector</code>; and, as with <code>tsvector</code>, any required normalization of words must be done before converting to the <code>tsquery</code> type. The <code>to_tsquery</code> function is convenient for performing such normalization:\n<code>\nSELECT to_tsquery('Fat:ab & Cats');\n to_tsquery \n------------------\n 'fat':AB & 'cat'\n</code>\nNote that <code>to_tsquery</code> will process prefixes in the same way as other words, which means this comparison returns true:\n<code>\nSELECT to_tsvector( 'postgraduate' ) @@ to_tsquery( 'postgres:*' );\n ?column?\n----------\n t\n</code>\nbecause <code>postgres</code> gets stemmed to <code>postgr</code>:\n<code>\nSELECT to_tsvector( 'postgraduate' ), to_tsquery( 'postgres:*' );\n to_tsvector | to_tsquery\n---------------+------------\n 'postgradu':1 | 'postgr':*\n</code>\nwhich will match the stemmed form of <code>postgraduate</code>.\n"
        ],
        "Tree": [
            "(identifier TSQUERY)"
        ]
    },
    {
        "Type": [
            "tsvector"
        ],
        "Description": [
            "text search document"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-textsearch.html",
        "Compensate": [
            "PostgreSQL provides two data types that are designed to support full text search, which is the activity of searching through a collection of natural-language documents to locate those that best match a query. The <code>tsvector</code> type represents a document in a form optimized for text search; the <code>tsquery</code> type similarly represents a text query. Chapter 12 provides a detailed explanation of this facility, and Section 9.13 summarizes the related functions and operators.",
            "\nA <code>tsvector</code> value is a sorted list of distinct lexemes, which are words that have been normalized to merge different variants of the same word (see Chapter 12 for details). Sorting and duplicate-elimination are done automatically during input, as shown in this example:\n<code>\nSELECT 'a fat cat sat on a mat and ate a fat rat'::tsvector;\n tsvector\n----------------------------------------------------\n 'a' 'and' 'ate' 'cat' 'fat' 'mat' 'on' 'rat' 'sat'\n</code>\nTo represent lexemes containing whitespace or punctuation, surround them with quotes:\n<code>\nSELECT $$the lexeme ' ' contains spaces$$::tsvector;\n tsvector \n-------------------------------------------\n ' ' 'contains' 'lexeme' 'spaces' 'the'\n</code>\n(We use dollar-quoted string literals in this example and the next one to avoid the confusion of having to double quote marks within the literals.) Embedded quotes and backslashes must be doubled:\n<code>\nSELECT $$the lexeme 'Joe''s' contains a quote$$::tsvector;\n tsvector \n------------------------------------------------\n 'Joe''s' 'a' 'contains' 'lexeme' 'quote' 'the'\n</code>\nOptionally, integer positions can be attached to lexemes:\n<code>\nSELECT 'a:1 fat:2 cat:3 sat:4 on:5 a:6 mat:7 and:8 ate:9 a:10 fat:11 rat:12'::tsvector;\n tsvector\n-------------------------------------------------------------------------------\n 'a':1,6,10 'and':8 'ate':9 'cat':3 'fat':2,11 'mat':7 'on':5 'rat':12 'sat':4\n</code>\nA position normally indicates the source word's location in the document. Positional information can be used for proximity ranking. Position values can range from 1 to 16383; larger numbers are silently set to 16383. Duplicate positions for the same lexeme are discarded.\nLexemes that have positions can further be labeled with a weight, which can be <code>A</code>, <code>B</code>, <code>C</code>, or <code>D</code>. <code>D</code> is the default and hence is not shown on output:\n<code>\nSELECT 'a:1A fat:2B,4C cat:5D'::tsvector;\n tsvector \n----------------------------\n 'a':1A 'cat':5 'fat':2B,4C\n</code>\nWeights are typically used to reflect document structure, for example by marking title words differently from body words. Text search ranking functions can assign different priorities to the different weight markers.\nIt is important to understand that the <code>tsvector</code> type itself does not perform any word normalization; it assumes the words it is given are normalized appropriately for the application. For example,\n<code>\nSELECT 'The Fat Rats'::tsvector;\n tsvector \n--------------------\n 'Fat' 'Rats' 'The'\n</code>\nFor most English-text-searching applications the above words would be considered non-normalized, but <code>tsvector</code> doesn't care. Raw document text should usually be passed through <code>to_tsvector</code> to normalize the words appropriately for searching:\n<code>\nSELECT to_tsvector('english', 'The Fat Rats');\n to_tsvector \n-----------------\n 'fat':2 'rat':3\n</code>\nAgain, see Chapter 12 for more detail.\n",
            "Optionally, lexemes in a <code>tsquery</code> can be labeled with one or more weight letters, which restricts them to match only <code>tsvector</code> lexemes with one of those weights:",
            "This query will match any word in a <code>tsvector</code> that begins with \"super\".",
            "Quoting rules for lexemes are the same as described previously for lexemes in <code>tsvector</code>; and, as with <code>tsvector</code>, any required normalization of words must be done before converting to the <code>tsquery</code> type. The <code>to_tsquery</code> function is convenient for performing such normalization:",
            "<code>\nSELECT to_tsvector( 'postgraduate' ) @@ to_tsquery( 'postgres:*' );\n ?column?\n----------\n t\n</code>",
            "<code>\nSELECT to_tsvector( 'postgraduate' ), to_tsquery( 'postgres:*' );\n to_tsvector | to_tsquery\n---------------+------------\n 'postgradu':1 | 'postgr':*\n</code>"
        ],
        "Tree": [
            "(identifier TSVECTOR)"
        ]
    },
    {
        "Type": [
            "uuid"
        ],
        "Description": [
            "universally unique identifier"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-uuid.html",
        "Compensate": [
            "The data type <code>uuid</code> stores Universally Unique Identifiers (UUID) as defined by RFC 4122, ISO/IEC 9834-8:2005, and related standards. (Some systems refer to this data type as a globally unique identifier, or GUID, instead.) This identifier is a 128-bit quantity that is generated by an algorithm chosen to make it very unlikely that the same identifier will be generated by anyone else in the known universe using the same algorithm. Therefore, for distributed systems, these identifiers provide a better uniqueness guarantee than sequence generators, which are only unique within a single database."
        ],
        "Tree": [
            "(identifier UUID)"
        ]
    },
    {
        "Type": [
            "xml"
        ],
        "Description": [
            "XML data"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-xml.html",
        "Compensate": [
            "The <code>xml</code> data type can be used to store XML data. Its advantage over storing XML data in a <code>text</code> field is that it checks the input values for well-formedness, and there are support functions to perform type-safe operations on it; see Section 9.14. Use of this data type requires the installation to have been built with <code>configure --with-libxml</code>.",
            "The <code>xml</code> type can store well-formed \"documents\", as defined by the XML standard, as well as \"content\" fragments, which are defined by reference to the more permissive \"document node\" of the XQuery and XPath data model. Roughly, this means that content fragments can have more than one top-level element or character node. The expression <code>xmlvalue IS DOCUMENT</code> can be used to evaluate whether a particular <code>xml</code> value is a full document or only a content fragment.",
            "Limits and compatibility notes for the <code>xml</code> data type can be found in Section D.3.",
            "\nTo produce a value of type <code>xml</code> from character data, use the function <code>xmlparse</code>:\n<code>\nXMLPARSE ( { DOCUMENT | CONTENT } <code>value</code>)\n</code>\nExamples:\n<code>\nXMLPARSE (DOCUMENT '<?xml version=\"1.0\"?><book><title>Manual</title><chapter>...</chapter></book>')\nXMLPARSE (CONTENT 'abc<foo>bar</foo><bar>foo</bar>')\n</code>\nWhile this is the only way to convert character strings into XML values according to the SQL standard, the PostgreSQL-specific syntaxes:\n<code>\nxml '<foo>bar</foo>'\n'<foo>bar</foo>'::xml\n</code>\ncan also be used.\nThe <code>xml</code> type does not validate input values against a document type declaration (DTD), even when the input value specifies a DTD. There is also currently no built-in support for validating against other XML schema languages such as XML Schema.\nThe inverse operation, producing a character string value from <code>xml</code>, uses the function <code>xmlserialize</code>:\n<code>\nXMLSERIALIZE ( { DOCUMENT | CONTENT } <code>value</code> AS <code>type</code> )\n</code>\n<code>type</code> can be <code>character</code>, <code>character varying</code>, or <code>text</code> (or an alias for one of those). Again, according to the SQL standard, this is the only way to convert between type <code>xml</code> and character types, but PostgreSQL also allows you to simply cast the value.\nWhen a character string value is cast to or from type <code>xml</code> without going through <code>XMLPARSE</code> or <code>XMLSERIALIZE</code>, respectively, the choice of <code>DOCUMENT</code> versus <code>CONTENT</code> is determined by the \"XML option\" session configuration parameter, which can be set using the standard command:\n<code>\nSET XML OPTION { DOCUMENT | CONTENT };\n</code>\nor the more PostgreSQL-like syntax\n<code>\nSET xmloption TO { DOCUMENT | CONTENT };\n</code>\nThe default is <code>CONTENT</code>, so all forms of XML data are allowed.\n",
            "Care must be taken when dealing with multiple character encodings on the client, server, and in the XML data passed through them. When using the text mode to pass queries to the server and query results to the client (which is the normal mode), PostgreSQL converts all character data passed between the client and the server and vice versa to the character encoding of the respective end; see Section 23.3. This includes string representations of XML values, such as in the above examples. This would ordinarily mean that encoding declarations contained in XML data can become invalid as the character data is converted to other encodings while traveling between client and server, because the embedded encoding declaration is not changed. To cope with this behavior, encoding declarations contained in character strings presented for input to the <code>xml</code> type are ignored, and content is assumed to be in the current server encoding. Consequently, for correct processing, character strings of XML data must be sent from the client in the current client encoding. It is the responsibility of the client to either convert documents to the current client encoding before sending them to the server, or to adjust the client encoding appropriately. On output, values of type <code>xml</code> will not have an encoding declaration, and clients should assume all data is in the current client encoding.",
            "Some XML-related functions may not work at all on non-ASCII data when the server encoding is not UTF-8. This is known to be an issue for <code>xmltable()</code> and <code>xpath()</code> in particular.",
            "\nThe <code>xml</code> data type is unusual in that it does not provide any comparison operators. This is because there is no well-defined and universally useful comparison algorithm for XML data. One consequence of this is that you cannot retrieve rows by comparing an <code>xml</code> column against a search value. XML values should therefore typically be accompanied by a separate key field such as an ID. An alternative solution for comparing XML values is to convert them to character strings first, but note that character string comparison has little to do with a useful XML comparison method.\nSince there are no comparison operators for the <code>xml</code> data type, it is not possible to create an index directly on a column of this type. If speedy searches in XML data are desired, possible workarounds include casting the expression to a character string type and indexing that, or indexing an XPath expression. Of course, the actual query would have to be adjusted to search by the indexed expression.\nThe text-search functionality in PostgreSQL can also be used to speed up full-document searches of XML data. The necessary preprocessing support is, however, not yet available in the PostgreSQL distribution.\n"
        ],
        "Tree": [
            "(unreserved_keyword XML)"
        ]
    },
    {
        "Type": [
            "json"
        ],
        "Description": [
            "textual JSON data"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-json.html",
        "Compensate": [
            "PostgreSQL offers two types for storing JSON data: <code>json</code> and <code>jsonb</code>. To implement efficient query mechanisms for these data types, PostgreSQL also provides the <code>jsonpath</code> data type described in Section 8.14.6.",
            "The <code>json</code> and <code>jsonb</code> data types accept almost identical sets of values as input. The major practical difference is one of efficiency. The <code>json</code> data type stores an exact copy of the input text, which processing functions must reparse on each execution; while <code>jsonb</code> data is stored in a decomposed binary format that makes it slightly slower to input due to added conversion overhead, but significantly faster to process, since no reparsing is needed. <code>jsonb</code> also supports indexing, which can be a significant advantage.",
            "Because the <code>json</code> type stores an exact copy of the input text, it will preserve semantically-insignificant white space between tokens, as well as the order of keys within JSON objects. Also, if a JSON object within the value contains the same key more than once, all the key/value pairs are kept. (The processing functions consider the last value as the operative one.) By contrast, <code>jsonb</code> does not preserve white space, does not preserve the order of object keys, and does not keep duplicate object keys. If duplicate keys are specified in the input, only the last value is kept.",
            "In general, most applications should prefer to store JSON data as <code>jsonb</code>, unless there are quite specialized needs, such as legacy assumptions about ordering of object keys.",
            "RFC 7159 permits JSON strings to contain Unicode escape sequences denoted by <code>\\uXXXX</code>. In the input function for the <code>json</code> type, Unicode escapes are allowed regardless of the database encoding, and are checked only for syntactic correctness (that is, that four hex digits follow <code>\\u</code>). However, the input function for <code>jsonb</code> is stricter: it disallows Unicode escapes for non-ASCII characters (those above <code>U+007F</code>) unless the database encoding is UTF8. The <code>jsonb</code> type also rejects <code>\\u0000</code> (because that cannot be represented in PostgreSQL's <code>text</code> type), and it insists that any use of Unicode surrogate pairs to designate characters outside the Unicode Basic Multilingual Plane be correct. Valid Unicode escapes are converted to the equivalent ASCII or UTF8 character for storage; this includes folding surrogate pairs into a single character.",
            "Many of the JSON processing functions described in Section 9.15 will convert Unicode escapes to regular characters, and will therefore throw the same types of errors just described even if their input is of type <code>json</code> not <code>jsonb</code>. The fact that the <code>json</code> input function does not make these checks may be considered a historical artifact, although it does allow for simple storage (without processing) of JSON Unicode escapes in a non-UTF8 database encoding. In general, it is best to avoid mixing Unicode escapes in JSON with a non-UTF8 database encoding, if possible.",
            "When converting textual JSON input into <code>jsonb</code>, the primitive types described by RFC 7159 are effectively mapped onto native PostgreSQL types, as shown in Table 8.23. Therefore, there are some minor additional constraints on what constitutes valid <code>jsonb</code> data that do not apply to the <code>json</code> type, nor to JSON in the abstract, corresponding to limits on what can be represented by the underlying data type. Notably, <code>jsonb</code> will reject numbers that are outside the range of the PostgreSQL <code>numeric</code> data type, while <code>json</code> will not. Such implementation-defined restrictions are permitted by RFC 7159. However, in practice such problems are far more likely to occur in other implementations, as it is common to represent JSON's <code>number</code> primitive type as IEEE 754 double precision floating point (which RFC 7159 explicitly anticipates and allows for). When using JSON as an interchange format with such systems, the danger of losing numeric precision compared to data originally stored by PostgreSQL should be considered.",
            "\nThe input/output syntax for the JSON data types is as specified in RFC 7159.\nThe following are all valid <code>json</code> (or <code>jsonb</code>) expressions:\n<code>\n-- Simple scalar/primitive value\n-- Primitive values can be numbers, quoted strings, true, false, or null\nSELECT '5'::json;\n-- Array of zero or more elements (elements need not be of same type)\nSELECT '[1, 2, \"foo\", null]'::json;\n-- Object containing pairs of keys and values\n-- Note that object keys must always be quoted strings\nSELECT '{\"bar\": \"baz\", \"balance\": 7.77, \"active\": false}'::json;\n-- Arrays and objects can be nested arbitrarily\nSELECT '{\"foo\": [true, \"bar\"], \"tags\": {\"a\": 1, \"b\": null}}'::json;\n</code>\nAs previously stated, when a JSON value is input and then printed without any additional processing, <code>json</code> outputs the same text that was input, while <code>jsonb</code> does not preserve semantically-insignificant details such as whitespace. For example, note the differences here:\n<code>\nSELECT '{\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}'::json;\n json \n-------------------------------------------------\n {\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}\n(1 row)\nSELECT '{\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}'::jsonb;\n jsonb \n--------------------------------------------------\n {\"bar\": \"baz\", \"active\": false, \"balance\": 7.77}\n(1 row)\n</code>\nOne semantically-insignificant detail worth noting is that in <code>jsonb</code>, numbers will be printed according to the behavior of the underlying <code>numeric</code> type. In practice this means that numbers entered with <code>E</code> notation will be printed without it, for example:\n<code>\nSELECT '{\"reading\": 1.230e-5}'::json, '{\"reading\": 1.230e-5}'::jsonb;\n json | jsonb \n-----------------------+-------------------------\n {\"reading\": 1.230e-5} | {\"reading\": 0.00001230}\n(1 row)\n</code>\nHowever, <code>jsonb</code> will preserve trailing fractional zeroes, as seen in this example, even though those are semantically insignificant for purposes such as equality checks.\nFor the list of built-in functions and operators available for constructing and processing JSON values, see Section 9.15.\n",
            "\nRepresenting data as JSON can be considerably more flexible than the traditional relational data model, which is compelling in environments where requirements are fluid. It is quite possible for both approaches to co-exist and complement each other within the same application. However, even for applications where maximal flexibility is desired, it is still recommended that JSON documents have a somewhat fixed structure. The structure is typically unenforced (though enforcing some business rules declaratively is possible), but having a predictable structure makes it easier to write queries that usefully summarize a set of \"documents\" (datums) in a table.\nJSON data is subject to the same concurrency-control considerations as any other data type when stored in a table. Although storing large documents is practicable, keep in mind that any update acquires a row-level lock on the whole row. Consider limiting JSON documents to a manageable size in order to decrease lock contention among updating transactions. Ideally, JSON documents should each represent an atomic datum that business rules dictate cannot reasonably be further subdivided into smaller datums that could be modified independently.\n",
            "\nTesting containment is an important capability of <code>jsonb</code>. There is no parallel set of facilities for the <code>json</code> type. Containment tests whether one <code>jsonb</code> document has contained within it another one. These examples return true except as noted:\n<code>\n-- Simple scalar/primitive values contain only the identical value:\nSELECT '\"foo\"'::jsonb @> '\"foo\"'::jsonb;\n-- The array on the right side is contained within the one on the left:\nSELECT '[1, 2, 3]'::jsonb @> '[1, 3]'::jsonb;\n-- Order of array elements is not significant, so this is also true:\nSELECT '[1, 2, 3]'::jsonb @> '[3, 1]'::jsonb;\n-- Duplicate array elements don't matter either:\nSELECT '[1, 2, 3]'::jsonb @> '[1, 2, 2]'::jsonb;\n-- The object with a single pair on the right side is contained\n-- within the object on the left side:\nSELECT '{\"product\": \"PostgreSQL\", \"version\": 9.4, \"jsonb\": true}'::jsonb @> '{\"version\": 9.4}'::jsonb;\n-- The array on the right side is not considered contained within the\n-- array on the left, even though a similar array is nested within it:\nSELECT '[1, 2, [1, 3]]'::jsonb @> '[1, 3]'::jsonb; -- yields false\n-- But with a layer of nesting, it is contained:\nSELECT '[1, 2, [1, 3]]'::jsonb @> '[[1, 3]]'::jsonb;\n-- Similarly, containment is not reported here:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb @> '{\"bar\": \"baz\"}'::jsonb; -- yields false\n-- A top-level key and an empty object is contained:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb @> '{\"foo\": {}}'::jsonb;\n</code>\nThe general principle is that the contained object must match the containing object as to structure and data contents, possibly after discarding some non-matching array elements or object key/value pairs from the containing object. But remember that the order of array elements is not significant when doing a containment match, and duplicate array elements are effectively considered only once.\nAs a special exception to the general principle that the structures must match, an array may contain a primitive value:\n<code>\n-- This array contains the primitive string value:\nSELECT '[\"foo\", \"bar\"]'::jsonb @> '\"bar\"'::jsonb;\n-- This exception is not reciprocal -- non-containment is reported here:\nSELECT '\"bar\"'::jsonb @> '[\"bar\"]'::jsonb; -- yields false\n</code>\n<code>jsonb</code> also has an existence operator, which is a variation on the theme of containment: it tests whether a string (given as a <code>text</code> value) appears as an object key or array element at the top level of the <code>jsonb</code> value. These examples return true except as noted:\n<code>\n-- String exists as array element:\nSELECT '[\"foo\", \"bar\", \"baz\"]'::jsonb ? 'bar';\n-- String exists as object key:\nSELECT '{\"foo\": \"bar\"}'::jsonb ? 'foo';\n-- Object values are not considered:\nSELECT '{\"foo\": \"bar\"}'::jsonb ? 'bar'; -- yields false\n-- As with containment, existence must match at the top level:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb ? 'bar'; -- yields false\n-- A string is considered to exist if it matches a primitive JSON string:\nSELECT '\"foo\"'::jsonb ? 'foo';\n</code>\nJSON objects are better suited than arrays for testing containment or existence when there are many keys or elements involved, because unlike arrays they are internally optimized for searching, and do not need to be searched linearly.\nTip\nBecause JSON containment is nested, an appropriate query can skip explicit selection of sub-objects. As an example, suppose that we have a <code>doc</code> column containing objects at the top level, with most objects containing <code>tags</code> fields that contain arrays of sub-objects. This query finds entries in which sub-objects containing both <code>\"term\":\"paris\"</code> and <code>\"term\":\"food\"</code> appear, while ignoring any such keys outside the <code>tags</code> array:\n<code>\nSELECT doc->'site_name' FROM websites\n WHERE doc @> '{\"tags\":[{\"term\":\"paris\"}, {\"term\":\"food\"}]}';\n</code>\nOne could accomplish the same thing with, say,\n<code>\nSELECT doc->'site_name' FROM websites\n WHERE doc->'tags' @> '[{\"term\":\"paris\"}, {\"term\":\"food\"}]';\n</code>\nbut that approach is less flexible, and often less efficient as well.\nOn the other hand, the JSON existence operator is not nested: it will only look for the specified key or array element at top level of the JSON value.\nThe various containment and existence operators, along with all other JSON operators and functions are documented in Section 9.15.\n",
            "\nGIN indexes can be used to efficiently search for keys or key/value pairs occurring within a large number of <code>jsonb</code> documents (datums). Two GIN \"operator classes\" are provided, offering different performance and flexibility trade-offs.\nThe default GIN operator class for <code>jsonb</code> supports queries with the key-exists operators <code>?</code>, <code>?|</code> and <code>?&</code>, the containment operator <code>@></code>, and the <code>jsonpath</code> match operators <code>@?</code> and <code>@@</code>. (For details of the semantics that these operators implement, see Table 9.45.) An example of creating an index with this operator class is:\n<code>\nCREATE INDEX idxgin ON api USING GIN (jdoc);\n</code>\nThe non-default GIN operator class <code>jsonb_path_ops</code> does not support the key-exists operators, but it does support <code>@></code>, <code>@?</code> and <code>@@</code>. An example of creating an index with this operator class is:\n<code>\nCREATE INDEX idxginp ON api USING GIN (jdoc jsonb_path_ops);\n</code>\nConsider the example of a table that stores JSON documents retrieved from a third-party web service, with a documented schema definition. A typical document is:\n<code>\n{\n \"guid\": \"9c36adc1-7fb5-4d5b-83b4-90356a46061a\",\n \"name\": \"Angela Barton\",\n \"is_active\": true,\n \"company\": \"Magnafone\",\n \"address\": \"178 Howard Place, Gulf, Washington, 702\",\n \"registered\": \"2009-11-07T08:53:22 +08:00\",\n \"latitude\": 19.793713,\n \"longitude\": 86.513373,\n \"tags\": [\n \"enim\",\n \"aliquip\",\n \"qui\"\n ]\n}\n</code>\nWe store these documents in a table named <code>api</code>, in a <code>jsonb</code> column named <code>jdoc</code>. If a GIN index is created on this column, queries like the following can make use of the index:\n<code>\n-- Find documents in which the key \"company\" has value \"Magnafone\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{\"company\": \"Magnafone\"}';\n</code>\nHowever, the index could not be used for queries like the following, because though the operator <code>?</code> is indexable, it is not applied directly to the indexed column <code>jdoc</code>:\n<code>\n-- Find documents in which the key \"tags\" contains key or array element \"qui\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc -> 'tags' ? 'qui';\n</code>\nStill, with appropriate use of expression indexes, the above query can use an index. If querying for particular items within the <code>\"tags\"</code> key is common, defining an index like this may be worthwhile:\n<code>\nCREATE INDEX idxgintags ON api USING GIN ((jdoc -> 'tags'));\n</code>\nNow, the <code>WHERE</code> clause <code>jdoc -> 'tags' ? 'qui'</code> will be recognized as an application of the indexable operator <code>?</code> to the indexed expression <code>jdoc -> 'tags'</code>. (More information on expression indexes can be found in Section 11.7.)\nAnother approach to querying is to exploit containment, for example:\n<code>\n-- Find documents in which the key \"tags\" contains array element \"qui\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{\"tags\": [\"qui\"]}';\n</code>\nA simple GIN index on the <code>jdoc</code> column can support this query. But note that such an index will store copies of every key and value in the <code>jdoc</code> column, whereas the expression index of the previous example stores only data found under the <code>tags</code> key. While the simple-index approach is far more flexible (since it supports queries about any key), targeted expression indexes are likely to be smaller and faster to search than a simple index.\nGIN indexes also support the <code>@?</code> and <code>@@</code> operators, which perform <code>jsonpath</code> matching. Examples are\n<code>\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @? '$.tags[*] ? (@ == \"qui\")';\n</code>\n<code>\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @@ '$.tags[*] == \"qui\"';\n</code>\nFor these operators, a GIN index extracts clauses of the form <code>accessors_chain = constant</code> out of the <code>jsonpath</code> pattern, and does the index search based on the keys and values mentioned in these clauses. The accessors chain may include <code>.key</code>, <code>[*]</code>, and <code>[index]</code> accessors. The <code>jsonb_ops</code> operator class also supports <code>.*</code> and <code>.**</code> accessors, but the <code>jsonb_path_ops</code> operator class does not.\nAlthough the <code>jsonb_path_ops</code> operator class supports only queries with the <code>@></code>, <code>@?</code> and <code>@@</code> operators, it has notable performance advantages over the default operator class <code>jsonb_ops</code>. A <code>jsonb_path_ops</code> index is usually much smaller than a <code>jsonb_ops</code> index over the same data, and the specificity of searches is better, particularly when queries contain keys that appear frequently in the data. Therefore search operations typically perform better than with the default operator class.\nThe technical difference between a <code>jsonb_ops</code> and a <code>jsonb_path_ops</code> GIN index is that the former creates independent index items for each key and value in the data, while the latter creates index items only for each value in the data. [6] Basically, each <code>jsonb_path_ops</code> index item is a hash of the value and the key(s) leading to it; for example to index <code>{\"foo\": {\"bar\": \"baz\"}}</code>, a single index item would be created incorporating all three of <code>foo</code>, <code>bar</code>, and <code>baz</code> into the hash value. Thus a containment query looking for this structure would result in an extremely specific index search; but there is no way at all to find out whether <code>foo</code> appears as a key. On the other hand, a <code>jsonb_ops</code> index would create three index items representing <code>foo</code>, <code>bar</code>, and <code>baz</code> separately; then to do the containment query, it would look for rows containing all three of these items. While GIN indexes can perform such an AND search fairly efficiently, it will still be less specific and slower than the equivalent <code>jsonb_path_ops</code> search, especially if there are a very large number of rows containing any single one of the three index items.\nA disadvantage of the <code>jsonb_path_ops</code> approach is that it produces no index entries for JSON structures not containing any values, such as <code>{\"a\": {}}</code>. If a search for documents containing such a structure is requested, it will require a full-index scan, which is quite slow. <code>jsonb_path_ops</code> is therefore ill-suited for applications that often perform such searches.\n<code>jsonb</code> also supports <code>btree</code> and <code>hash</code> indexes. These are usually useful only if it's important to check equality of complete JSON documents. The <code>btree</code> ordering for <code>jsonb</code> datums is seldom of great interest, but for completeness it is:\n<code>\n<code>Object</code> > <code>Array</code> > <code>Boolean</code> > <code>Number</code> > <code>String</code> > <code>Null</code>\n<code>Object with n pairs</code> > <code>object with n - 1 pairs</code>\n<code>Array with n elements</code> > <code>array with n - 1 elements</code>\n</code>\nObjects with equal numbers of pairs are compared in the order:\n<code>\n<code>key-1</code>, <code>value-1</code>, <code>key-2</code> ...\n</code>\nNote that object keys are compared in their storage order; in particular, since shorter keys are stored before longer keys, this can lead to results that might be unintuitive, such as:\n<code>\n{ \"aa\": 1, \"c\": 1} > {\"b\": 1, \"d\": 1}\n</code>\nSimilarly, arrays with equal numbers of elements are compared in the order:\n<code>\n<code>element-1</code>, <code>element-2</code> ...\n</code>\nPrimitive JSON values are compared using the same comparison rules as for the underlying PostgreSQL data type. Strings are compared using the default database collation.\n",
            "Additional extensions are available that implement transforms for the <code>jsonb</code> type for different procedural languages.",
            "The extensions for PL/Perl are called <code>jsonb_plperl</code> and <code>jsonb_plperlu</code>. If you use them, <code>jsonb</code> values are mapped to Perl arrays, hashes, and scalars, as appropriate.",
            "The extensions for PL/Python are called <code>jsonb_plpythonu</code>, <code>jsonb_plpython2u</code>, and <code>jsonb_plpython3u</code> (see Section 45.1 for the PL/Python naming convention). If you use them, <code>jsonb</code> values are mapped to Python dictionaries, lists, and scalars, as appropriate.",
            "\nThe <code>jsonpath</code> type implements support for the SQL/JSON path language in PostgreSQL to efficiently query JSON data. It provides a binary representation of the parsed SQL/JSON path expression that specifies the items to be retrieved by the path engine from the JSON data for further processing with the SQL/JSON query functions.\nThe semantics of SQL/JSON path predicates and operators generally follow SQL. At the same time, to provide a most natural way of working with JSON data, SQL/JSON path syntax uses some of the JavaScript conventions:\nDot (<code>.</code>) is used for member access.\nSquare brackets (<code>[]</code>) are used for array access.\nSQL/JSON arrays are 0-relative, unlike regular SQL arrays that start from 1.\nAn SQL/JSON path expression is typically written in an SQL query as an SQL character string literal, so it must be enclosed in single quotes, and any single quotes desired within the value must be doubled (see Section 4.1.2.1). Some forms of path expressions require string literals within them. These embedded string literals follow JavaScript/ECMAScript conventions: they must be surrounded by double quotes, and backslash escapes may be used within them to represent otherwise-hard-to-type characters. In particular, the way to write a double quote within an embedded string literal is <code>\\\"</code>, and to write a backslash itself, you must write <code>\\\\</code>. Other special backslash sequences include those recognized in JavaScript strings: <code>\\b</code>, <code>\\f</code>, <code>\\n</code>, <code>\\r</code>, <code>\\t</code>, <code>\\v</code> for various ASCII control characters, <code>\\xNN</code> for a character code written with only two hex digits, <code>\\uNNNN</code> for a Unicode character identified by its 4-hex-digit code point, and <code>\\u{N...}</code> for a Unicode character code point written with 1 to 6 hex digits.\nA path expression consists of a sequence of path elements, which can be the following:\nPath literals of JSON primitive types: Unicode text, numeric, true, false, or null.\nPath variables listed in Table 8.24.\nAccessor operators listed in Table 8.25.\n<code>jsonpath</code> operators and methods listed in Section 9.15.2.3\nParentheses, which can be used to provide filter expressions or define the order of path evaluation.\nFor details on using <code>jsonpath</code> expressions with SQL/JSON query functions, see Section 9.15.2.\nTable 8.24. <code>jsonpath</code> Variables\n<table>\n<thead>\n<tr>\n<th>Variable</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td><code>$</code></td>\n<td>A variable representing the JSON text to be queried (the context item).</td>\n</tr>\n<tr>\n<td><code>$varname</code></td>\n<td>A named variable. Its value can be set by the parameter <code>vars</code> of several JSON processing functions. See <link>Table 9.47&LINK&https://www.postgresql.org/docs/12/functions-json.html#FUNCTIONS-JSON-PROCESSING-TABLE</link> and its notes for details.</td>\n</tr>\n<tr>\n<td><code>@</code></td>\n<td>A variable representing the result of path evaluation in filter expressions.</td>\n</tr>\n</tbody>\n</table>\nTable 8.25. <code>jsonpath</code> Accessors\n<table>\n<thead>\n<tr>\n<th>Accessor Operator</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>\n<code>.key</code>\n<code>.\"$varname\"</code>\n</td>\n<td>\nMember accessor that returns an object member with the specified key. If the key name is a named variable starting with <code>$</code> or does not meet the JavaScript rules of an identifier, it must be enclosed in double quotes as a character string literal.\n</td>\n</tr>\n<tr>\n<td>\n<code>.*</code>\n</td>\n<td>\nWildcard member accessor that returns the values of all members located at the top level of the current object.\n</td>\n</tr>\n<tr>\n<td>\n<code>.**</code>\n</td>\n<td>\nRecursive wildcard member accessor that processes all levels of the JSON hierarchy of the current object and returns all the member values, regardless of their nesting level. This is a PostgreSQL extension of the SQL/JSON standard.\n</td>\n</tr>\n<tr>\n<td>\n<code>.**{level}</code>\n<code>.**{start_level to end_level}</code>\n</td>\n<td>\nSame as <code>.**</code>, but with a filter over nesting levels of JSON hierarchy. Nesting levels are specified as integers. Zero level corresponds to the current object. To access the lowest nesting level, you can use the <code>last</code> keyword. This is a PostgreSQL extension of the SQL/JSON standard.\n</td>\n</tr>\n<tr>\n<td>\n<code>[subscript, ...]</code>\n</td>\n<td>\nArray element accessor. <code>subscript</code> can be given in two forms: <code>index</code> or <code>start_index to end_index</code>. The first form returns a single array element by its index. The second form returns an array slice by the range of indexes, including the elements that correspond to the provided <code>start_index</code> and <code>end_index</code>.\nThe specified <code>index</code> can be an integer, as well as an expression returning a single numeric value, which is automatically cast to integer. Zero index corresponds to the first array element. You can also use the <code>last</code> keyword to denote the last array element, which is useful for handling arrays of unknown length.\n</td>\n</tr>\n<tr>\n<td>\n<code>[*]</code>\n</td>\n<td>\nWildcard array element accessor that returns all array elements.\n</td>\n</tr>\n</tbody>\n</table>\n[6] For this purpose, the term \"value\" includes array elements, though JSON terminology sometimes considers array elements distinct from values within objects.\n"
        ],
        "Tree": [
            "(identifier JSON)"
        ]
    },
    {
        "Type": [
            "jsonb"
        ],
        "Description": [
            "binary JSON data, decomposed"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-json.html",
        "Compensate": [
            "PostgreSQL offers two types for storing JSON data: <code>json</code> and <code>jsonb</code>. To implement efficient query mechanisms for these data types, PostgreSQL also provides the <code>jsonpath</code> data type described in Section 8.14.6.",
            "The <code>json</code> and <code>jsonb</code> data types accept almost identical sets of values as input. The major practical difference is one of efficiency. The <code>json</code> data type stores an exact copy of the input text, which processing functions must reparse on each execution; while <code>jsonb</code> data is stored in a decomposed binary format that makes it slightly slower to input due to added conversion overhead, but significantly faster to process, since no reparsing is needed. <code>jsonb</code> also supports indexing, which can be a significant advantage.",
            "Because the <code>json</code> type stores an exact copy of the input text, it will preserve semantically-insignificant white space between tokens, as well as the order of keys within JSON objects. Also, if a JSON object within the value contains the same key more than once, all the key/value pairs are kept. (The processing functions consider the last value as the operative one.) By contrast, <code>jsonb</code> does not preserve white space, does not preserve the order of object keys, and does not keep duplicate object keys. If duplicate keys are specified in the input, only the last value is kept.",
            "In general, most applications should prefer to store JSON data as <code>jsonb</code>, unless there are quite specialized needs, such as legacy assumptions about ordering of object keys.",
            "RFC 7159 permits JSON strings to contain Unicode escape sequences denoted by <code>\\uXXXX</code>. In the input function for the <code>json</code> type, Unicode escapes are allowed regardless of the database encoding, and are checked only for syntactic correctness (that is, that four hex digits follow <code>\\u</code>). However, the input function for <code>jsonb</code> is stricter: it disallows Unicode escapes for non-ASCII characters (those above <code>U+007F</code>) unless the database encoding is UTF8. The <code>jsonb</code> type also rejects <code>\\u0000</code> (because that cannot be represented in PostgreSQL's <code>text</code> type), and it insists that any use of Unicode surrogate pairs to designate characters outside the Unicode Basic Multilingual Plane be correct. Valid Unicode escapes are converted to the equivalent ASCII or UTF8 character for storage; this includes folding surrogate pairs into a single character.",
            "Many of the JSON processing functions described in Section 9.15 will convert Unicode escapes to regular characters, and will therefore throw the same types of errors just described even if their input is of type <code>json</code> not <code>jsonb</code>. The fact that the <code>json</code> input function does not make these checks may be considered a historical artifact, although it does allow for simple storage (without processing) of JSON Unicode escapes in a non-UTF8 database encoding. In general, it is best to avoid mixing Unicode escapes in JSON with a non-UTF8 database encoding, if possible.",
            "When converting textual JSON input into <code>jsonb</code>, the primitive types described by RFC 7159 are effectively mapped onto native PostgreSQL types, as shown in Table 8.23. Therefore, there are some minor additional constraints on what constitutes valid <code>jsonb</code> data that do not apply to the <code>json</code> type, nor to JSON in the abstract, corresponding to limits on what can be represented by the underlying data type. Notably, <code>jsonb</code> will reject numbers that are outside the range of the PostgreSQL <code>numeric</code> data type, while <code>json</code> will not. Such implementation-defined restrictions are permitted by RFC 7159. However, in practice such problems are far more likely to occur in other implementations, as it is common to represent JSON's <code>number</code> primitive type as IEEE 754 double precision floating point (which RFC 7159 explicitly anticipates and allows for). When using JSON as an interchange format with such systems, the danger of losing numeric precision compared to data originally stored by PostgreSQL should be considered.",
            "The following are all valid <code>json</code> (or <code>jsonb</code>) expressions:",
            "As previously stated, when a JSON value is input and then printed without any additional processing, <code>json</code> outputs the same text that was input, while <code>jsonb</code> does not preserve semantically-insignificant details such as whitespace. For example, note the differences here:",
            "<code>\nSELECT '{\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}'::json;\n json \n-------------------------------------------------\n {\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}\n(1 row)\nSELECT '{\"bar\": \"baz\", \"balance\": 7.77, \"active\":false}'::jsonb;\n jsonb \n--------------------------------------------------\n {\"bar\": \"baz\", \"active\": false, \"balance\": 7.77}\n(1 row)\n</code>",
            "One semantically-insignificant detail worth noting is that in <code>jsonb</code>, numbers will be printed according to the behavior of the underlying <code>numeric</code> type. In practice this means that numbers entered with <code>E</code> notation will be printed without it, for example:",
            "<code>\nSELECT '{\"reading\": 1.230e-5}'::json, '{\"reading\": 1.230e-5}'::jsonb;\n json | jsonb \n-----------------------+-------------------------\n {\"reading\": 1.230e-5} | {\"reading\": 0.00001230}\n(1 row)\n</code>",
            "However, <code>jsonb</code> will preserve trailing fractional zeroes, as seen in this example, even though those are semantically insignificant for purposes such as equality checks.",
            "\nTesting containment is an important capability of <code>jsonb</code>. There is no parallel set of facilities for the <code>json</code> type. Containment tests whether one <code>jsonb</code> document has contained within it another one. These examples return true except as noted:\n<code>\n-- Simple scalar/primitive values contain only the identical value:\nSELECT '\"foo\"'::jsonb @> '\"foo\"'::jsonb;\n-- The array on the right side is contained within the one on the left:\nSELECT '[1, 2, 3]'::jsonb @> '[1, 3]'::jsonb;\n-- Order of array elements is not significant, so this is also true:\nSELECT '[1, 2, 3]'::jsonb @> '[3, 1]'::jsonb;\n-- Duplicate array elements don't matter either:\nSELECT '[1, 2, 3]'::jsonb @> '[1, 2, 2]'::jsonb;\n-- The object with a single pair on the right side is contained\n-- within the object on the left side:\nSELECT '{\"product\": \"PostgreSQL\", \"version\": 9.4, \"jsonb\": true}'::jsonb @> '{\"version\": 9.4}'::jsonb;\n-- The array on the right side is not considered contained within the\n-- array on the left, even though a similar array is nested within it:\nSELECT '[1, 2, [1, 3]]'::jsonb @> '[1, 3]'::jsonb; -- yields false\n-- But with a layer of nesting, it is contained:\nSELECT '[1, 2, [1, 3]]'::jsonb @> '[[1, 3]]'::jsonb;\n-- Similarly, containment is not reported here:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb @> '{\"bar\": \"baz\"}'::jsonb; -- yields false\n-- A top-level key and an empty object is contained:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb @> '{\"foo\": {}}'::jsonb;\n</code>\nThe general principle is that the contained object must match the containing object as to structure and data contents, possibly after discarding some non-matching array elements or object key/value pairs from the containing object. But remember that the order of array elements is not significant when doing a containment match, and duplicate array elements are effectively considered only once.\nAs a special exception to the general principle that the structures must match, an array may contain a primitive value:\n<code>\n-- This array contains the primitive string value:\nSELECT '[\"foo\", \"bar\"]'::jsonb @> '\"bar\"'::jsonb;\n-- This exception is not reciprocal -- non-containment is reported here:\nSELECT '\"bar\"'::jsonb @> '[\"bar\"]'::jsonb; -- yields false\n</code>\n<code>jsonb</code> also has an existence operator, which is a variation on the theme of containment: it tests whether a string (given as a <code>text</code> value) appears as an object key or array element at the top level of the <code>jsonb</code> value. These examples return true except as noted:\n<code>\n-- String exists as array element:\nSELECT '[\"foo\", \"bar\", \"baz\"]'::jsonb ? 'bar';\n-- String exists as object key:\nSELECT '{\"foo\": \"bar\"}'::jsonb ? 'foo';\n-- Object values are not considered:\nSELECT '{\"foo\": \"bar\"}'::jsonb ? 'bar'; -- yields false\n-- As with containment, existence must match at the top level:\nSELECT '{\"foo\": {\"bar\": \"baz\"}}'::jsonb ? 'bar'; -- yields false\n-- A string is considered to exist if it matches a primitive JSON string:\nSELECT '\"foo\"'::jsonb ? 'foo';\n</code>\nJSON objects are better suited than arrays for testing containment or existence when there are many keys or elements involved, because unlike arrays they are internally optimized for searching, and do not need to be searched linearly.\nTip\nBecause JSON containment is nested, an appropriate query can skip explicit selection of sub-objects. As an example, suppose that we have a <code>doc</code> column containing objects at the top level, with most objects containing <code>tags</code> fields that contain arrays of sub-objects. This query finds entries in which sub-objects containing both <code>\"term\":\"paris\"</code> and <code>\"term\":\"food\"</code> appear, while ignoring any such keys outside the <code>tags</code> array:\n<code>\nSELECT doc->'site_name' FROM websites\n WHERE doc @> '{\"tags\":[{\"term\":\"paris\"}, {\"term\":\"food\"}]}';\n</code>\nOne could accomplish the same thing with, say,\n<code>\nSELECT doc->'site_name' FROM websites\n WHERE doc->'tags' @> '[{\"term\":\"paris\"}, {\"term\":\"food\"}]';\n</code>\nbut that approach is less flexible, and often less efficient as well.\nOn the other hand, the JSON existence operator is not nested: it will only look for the specified key or array element at top level of the JSON value.\nThe various containment and existence operators, along with all other JSON operators and functions are documented in Section 9.15.\n",
            "\nGIN indexes can be used to efficiently search for keys or key/value pairs occurring within a large number of <code>jsonb</code> documents (datums). Two GIN \"operator classes\" are provided, offering different performance and flexibility trade-offs.\nThe default GIN operator class for <code>jsonb</code> supports queries with the key-exists operators <code>?</code>, <code>?|</code> and <code>?&</code>, the containment operator <code>@></code>, and the <code>jsonpath</code> match operators <code>@?</code> and <code>@@</code>. (For details of the semantics that these operators implement, see Table 9.45.) An example of creating an index with this operator class is:\n<code>\nCREATE INDEX idxgin ON api USING GIN (jdoc);\n</code>\nThe non-default GIN operator class <code>jsonb_path_ops</code> does not support the key-exists operators, but it does support <code>@></code>, <code>@?</code> and <code>@@</code>. An example of creating an index with this operator class is:\n<code>\nCREATE INDEX idxginp ON api USING GIN (jdoc jsonb_path_ops);\n</code>\nConsider the example of a table that stores JSON documents retrieved from a third-party web service, with a documented schema definition. A typical document is:\n<code>\n{\n \"guid\": \"9c36adc1-7fb5-4d5b-83b4-90356a46061a\",\n \"name\": \"Angela Barton\",\n \"is_active\": true,\n \"company\": \"Magnafone\",\n \"address\": \"178 Howard Place, Gulf, Washington, 702\",\n \"registered\": \"2009-11-07T08:53:22 +08:00\",\n \"latitude\": 19.793713,\n \"longitude\": 86.513373,\n \"tags\": [\n \"enim\",\n \"aliquip\",\n \"qui\"\n ]\n}\n</code>\nWe store these documents in a table named <code>api</code>, in a <code>jsonb</code> column named <code>jdoc</code>. If a GIN index is created on this column, queries like the following can make use of the index:\n<code>\n-- Find documents in which the key \"company\" has value \"Magnafone\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{\"company\": \"Magnafone\"}';\n</code>\nHowever, the index could not be used for queries like the following, because though the operator <code>?</code> is indexable, it is not applied directly to the indexed column <code>jdoc</code>:\n<code>\n-- Find documents in which the key \"tags\" contains key or array element \"qui\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc -> 'tags' ? 'qui';\n</code>\nStill, with appropriate use of expression indexes, the above query can use an index. If querying for particular items within the <code>\"tags\"</code> key is common, defining an index like this may be worthwhile:\n<code>\nCREATE INDEX idxgintags ON api USING GIN ((jdoc -> 'tags'));\n</code>\nNow, the <code>WHERE</code> clause <code>jdoc -> 'tags' ? 'qui'</code> will be recognized as an application of the indexable operator <code>?</code> to the indexed expression <code>jdoc -> 'tags'</code>. (More information on expression indexes can be found in Section 11.7.)\nAnother approach to querying is to exploit containment, for example:\n<code>\n-- Find documents in which the key \"tags\" contains array element \"qui\"\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @> '{\"tags\": [\"qui\"]}';\n</code>\nA simple GIN index on the <code>jdoc</code> column can support this query. But note that such an index will store copies of every key and value in the <code>jdoc</code> column, whereas the expression index of the previous example stores only data found under the <code>tags</code> key. While the simple-index approach is far more flexible (since it supports queries about any key), targeted expression indexes are likely to be smaller and faster to search than a simple index.\nGIN indexes also support the <code>@?</code> and <code>@@</code> operators, which perform <code>jsonpath</code> matching. Examples are\n<code>\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @? '$.tags[*] ? (@ == \"qui\")';\n</code>\n<code>\nSELECT jdoc->'guid', jdoc->'name' FROM api WHERE jdoc @@ '$.tags[*] == \"qui\"';\n</code>\nFor these operators, a GIN index extracts clauses of the form <code>accessors_chain = constant</code> out of the <code>jsonpath</code> pattern, and does the index search based on the keys and values mentioned in these clauses. The accessors chain may include <code>.key</code>, <code>[*]</code>, and <code>[index]</code> accessors. The <code>jsonb_ops</code> operator class also supports <code>.*</code> and <code>.**</code> accessors, but the <code>jsonb_path_ops</code> operator class does not.\nAlthough the <code>jsonb_path_ops</code> operator class supports only queries with the <code>@></code>, <code>@?</code> and <code>@@</code> operators, it has notable performance advantages over the default operator class <code>jsonb_ops</code>. A <code>jsonb_path_ops</code> index is usually much smaller than a <code>jsonb_ops</code> index over the same data, and the specificity of searches is better, particularly when queries contain keys that appear frequently in the data. Therefore search operations typically perform better than with the default operator class.\nThe technical difference between a <code>jsonb_ops</code> and a <code>jsonb_path_ops</code> GIN index is that the former creates independent index items for each key and value in the data, while the latter creates index items only for each value in the data. [6] Basically, each <code>jsonb_path_ops</code> index item is a hash of the value and the key(s) leading to it; for example to index <code>{\"foo\": {\"bar\": \"baz\"}}</code>, a single index item would be created incorporating all three of <code>foo</code>, <code>bar</code>, and <code>baz</code> into the hash value. Thus a containment query looking for this structure would result in an extremely specific index search; but there is no way at all to find out whether <code>foo</code> appears as a key. On the other hand, a <code>jsonb_ops</code> index would create three index items representing <code>foo</code>, <code>bar</code>, and <code>baz</code> separately; then to do the containment query, it would look for rows containing all three of these items. While GIN indexes can perform such an AND search fairly efficiently, it will still be less specific and slower than the equivalent <code>jsonb_path_ops</code> search, especially if there are a very large number of rows containing any single one of the three index items.\nA disadvantage of the <code>jsonb_path_ops</code> approach is that it produces no index entries for JSON structures not containing any values, such as <code>{\"a\": {}}</code>. If a search for documents containing such a structure is requested, it will require a full-index scan, which is quite slow. <code>jsonb_path_ops</code> is therefore ill-suited for applications that often perform such searches.\n<code>jsonb</code> also supports <code>btree</code> and <code>hash</code> indexes. These are usually useful only if it's important to check equality of complete JSON documents. The <code>btree</code> ordering for <code>jsonb</code> datums is seldom of great interest, but for completeness it is:\n<code>\n<code>Object</code> > <code>Array</code> > <code>Boolean</code> > <code>Number</code> > <code>String</code> > <code>Null</code>\n<code>Object with n pairs</code> > <code>object with n - 1 pairs</code>\n<code>Array with n elements</code> > <code>array with n - 1 elements</code>\n</code>\nObjects with equal numbers of pairs are compared in the order:\n<code>\n<code>key-1</code>, <code>value-1</code>, <code>key-2</code> ...\n</code>\nNote that object keys are compared in their storage order; in particular, since shorter keys are stored before longer keys, this can lead to results that might be unintuitive, such as:\n<code>\n{ \"aa\": 1, \"c\": 1} > {\"b\": 1, \"d\": 1}\n</code>\nSimilarly, arrays with equal numbers of elements are compared in the order:\n<code>\n<code>element-1</code>, <code>element-2</code> ...\n</code>\nPrimitive JSON values are compared using the same comparison rules as for the underlying PostgreSQL data type. Strings are compared using the default database collation.\n",
            "Additional extensions are available that implement transforms for the <code>jsonb</code> type for different procedural languages.",
            "The extensions for PL/Perl are called <code>jsonb_plperl</code> and <code>jsonb_plperlu</code>. If you use them, <code>jsonb</code> values are mapped to Perl arrays, hashes, and scalars, as appropriate.",
            "The extensions for PL/Python are called <code>jsonb_plpythonu</code>, <code>jsonb_plpython2u</code>, and <code>jsonb_plpython3u</code> (see Section 45.1 for the PL/Python naming convention). If you use them, <code>jsonb</code> values are mapped to Python dictionaries, lists, and scalars, as appropriate."
        ],
        "Tree": [
            "(identifier JSONB)"
        ]
    },
    {
        "Type": [
            "pg_lsn"
        ],
        "Description": [
            "PostgreSQL Log Sequence Number"
        ],
        "Link": "https://www.postgresql.org/docs/12/datatype-pg-lsn.html",
        "Compensate": [
            "The <code>pg_lsn</code> data type can be used to store LSN (Log Sequence Number) data which is a pointer to a location in the WAL. This type is a representation of <code>XLogRecPtr</code> and an internal system type of PostgreSQL.",
            "Internally, an LSN is a 64-bit integer, representing a byte position in the write-ahead log stream. It is printed as two hexadecimal numbers of up to 8 digits each, separated by a slash; for example, <code>16/B374D848</code>. The <code>pg_lsn</code> type supports the standard comparison operators, like <code>=</code> and <code>></code>. Two LSNs can be subtracted using the <code>-</code> operator; the result is the number of bytes separating those write-ahead log locations."
        ],
        "Tree": [
            "(identifier PG_LSN)"
        ]
    },
    {
        "Type": [
            "int4range"
        ],
        "Description": [
            "Range of integer"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [
            "<code>\nCREATE TABLE reservation (room int, during tsrange);\nINSERT INTO reservation VALUES\n (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');\n-- Containment\nSELECT int4range(10, 20) @> 3;\n-- Overlaps\nSELECT numrange(11.1, 22.2) && numrange(20.0, 30.0);\n-- Extract the upper bound\nSELECT upper(int8range(15, 25));\n-- Compute the intersection\nSELECT int4range(10, 20) * int4range(15, 25);\n-- Is the range empty?\nSELECT isempty(numrange(1, 5));\n</code>",
            "<code>\n-- includes 3, does not include 7, and does include all points in between\nSELECT '[3,7)'::int4range;\n-- does not include either 3 or 7, but includes all points in between\nSELECT '(3,7)'::int4range;\n-- includes only the single point 4\nSELECT '[4,4]'::int4range;\n-- includes no points (and will be normalized to 'empty')\nSELECT '[4,4)'::int4range;\n</code>",
            "The built-in range types <code>int4range</code>, <code>int8range</code>, and <code>daterange</code> all use a canonical form that includes the lower bound and excludes the upper bound; that is, <code>[)</code>. User-defined range types can use other conventions, however."
        ],
        "Tree": [
            "(identifier INT4RANGE)"
        ]
    },
    {
        "Type": [
            "int8range"
        ],
        "Description": [
            "Range of bigint"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [
            "<code>\nCREATE TABLE reservation (room int, during tsrange);\nINSERT INTO reservation VALUES\n (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');\n-- Containment\nSELECT int4range(10, 20) @> 3;\n-- Overlaps\nSELECT numrange(11.1, 22.2) && numrange(20.0, 30.0);\n-- Extract the upper bound\nSELECT upper(int8range(15, 25));\n-- Compute the intersection\nSELECT int4range(10, 20) * int4range(15, 25);\n-- Is the range empty?\nSELECT isempty(numrange(1, 5));\n</code>",
            "<code>\n-- The full form is: lower bound, upper bound, and text argument indicating\n-- inclusivity/exclusivity of bounds.\nSELECT numrange(1.0, 14.0, '(]');\n-- If the third argument is omitted, '[)' is assumed.\nSELECT numrange(1.0, 14.0);\n-- Although '(]' is specified here, on display the value will be converted to\n-- canonical form, since int8range is a discrete range type (see below).\nSELECT int8range(1, 14, '(]');\n-- Using NULL for either bound causes the range to be unbounded on that side.\nSELECT numrange(NULL, 2.2);\n</code>",
            "The built-in range types <code>int4range</code>, <code>int8range</code>, and <code>daterange</code> all use a canonical form that includes the lower bound and excludes the upper bound; that is, <code>[)</code>. User-defined range types can use other conventions, however."
        ],
        "Tree": [
            "(identifier INT8RANGE)"
        ]
    },
    {
        "Type": [
            "numrange"
        ],
        "Description": [
            "Range of numericr"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [
            "<code>\nCREATE TABLE reservation (room int, during tsrange);\nINSERT INTO reservation VALUES\n (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');\n-- Containment\nSELECT int4range(10, 20) @> 3;\n-- Overlaps\nSELECT numrange(11.1, 22.2) && numrange(20.0, 30.0);\n-- Extract the upper bound\nSELECT upper(int8range(15, 25));\n-- Compute the intersection\nSELECT int4range(10, 20) * int4range(15, 25);\n-- Is the range empty?\nSELECT isempty(numrange(1, 5));\n</code>",
            "<code>\n-- The full form is: lower bound, upper bound, and text argument indicating\n-- inclusivity/exclusivity of bounds.\nSELECT numrange(1.0, 14.0, '(]');\n-- If the third argument is omitted, '[)' is assumed.\nSELECT numrange(1.0, 14.0);\n-- Although '(]' is specified here, on display the value will be converted to\n-- canonical form, since int8range is a discrete range type (see below).\nSELECT int8range(1, 14, '(]');\n-- Using NULL for either bound causes the range to be unbounded on that side.\nSELECT numrange(NULL, 2.2);\n</code>"
        ],
        "Tree": [
            "(identifier NUMRANGE)"
        ]
    },
    {
        "Type": [
            "tsrange"
        ],
        "Description": [
            "Range of timestamp without time zone"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [
            "Range types are data types representing a range of values of some element type (called the range's subtype). For instance, ranges of <code>timestamp</code> might be used to represent the ranges of time that a meeting room is reserved. In this case the data type is <code>tsrange</code> (short for \"timestamp range\"), and <code>timestamp</code> is the subtype. The subtype must have a total order so that it is well-defined whether element values are within, before, or after a range of values.",
            "<code>\nCREATE TABLE reservation (room int, during tsrange);\nINSERT INTO reservation VALUES\n (1108, '[2010-01-01 14:30, 2010-01-01 15:30)');\n-- Containment\nSELECT int4range(10, 20) @> 3;\n-- Overlaps\nSELECT numrange(11.1, 22.2) && numrange(20.0, 30.0);\n-- Extract the upper bound\nSELECT upper(int8range(15, 25));\n-- Compute the intersection\nSELECT int4range(10, 20) * int4range(15, 25);\n-- Is the range empty?\nSELECT isempty(numrange(1, 5));\n</code>",
            "<code>\nCREATE TABLE reservation (\n during tsrange,\n EXCLUDE USING GIST (during WITH &&)\n);\n</code>",
            "<code>\nCREATE EXTENSION btree_gist;\nCREATE TABLE room_reservation (\n room text,\n during tsrange,\n EXCLUDE USING GIST (room WITH =, during WITH &&)\n);\nINSERT INTO room_reservation VALUES\n ('123A', '[2010-01-01 14:00, 2010-01-01 15:00)');\nINSERT 0 1\nINSERT INTO room_reservation VALUES\n ('123A', '[2010-01-01 14:30, 2010-01-01 15:30)');\nERROR: conflicting key value violates exclusion constraint \"room_reservation_room_during_excl\"\nDETAIL: Key (room, during)=(123A, [\"2010-01-01 14:30:00\",\"2010-01-01 15:30:00\")) conflicts\nwith existing key (room, during)=(123A, [\"2010-01-01 14:00:00\",\"2010-01-01 15:00:00\")).\nINSERT INTO room_reservation VALUES\n ('123B', '[2010-01-01 14:30, 2010-01-01 15:30)');\nINSERT 0 1\n</code>"
        ],
        "Tree": [
            "(identifier TSRANGE)"
        ]
    },
    {
        "Type": [
            "tstzrange"
        ],
        "Description": [
            "Range of timestamp with time zone"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [],
        "Tree": [
            "(identifier TSTZRANGE)"
        ]
    },
    {
        "Type": [
            "daterange"
        ],
        "Description": [
            "Range of date"
        ],
        "Link": "https://www.postgresql.org/docs/12/rangetypes.html",
        "Compensate": [
            "The built-in range types <code>int4range</code>, <code>int8range</code>, and <code>daterange</code> all use a canonical form that includes the lower bound and excludes the upper bound; that is, <code>[)</code>. User-defined range types can use other conventions, however."
        ],
        "Tree": [
            "(identifier DATERANGE)"
        ]
    }
]